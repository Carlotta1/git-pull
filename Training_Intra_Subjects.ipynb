{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from torch import backends\n",
    "from beautifultable import BeautifulTable\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##SETTINGS\n",
    "doTrain = True\n",
    "doEval = True\n",
    "\n",
    "nfold = 10 #number of folds to train\n",
    "fold_offset = 1\n",
    "lr=0.01 #learning rate\n",
    "\n",
    "batch_size = 32\n",
    "val_split = .1 #trainset percentage allocated for devset\n",
    "test_val_split = .1 #trainset percentage allocated for test_val set (i.e. the test set of known patients)\n",
    "\n",
    "#cwd = os.getcwd()\n",
    "subject = 1 # serve per caricare le folds da cartelle diverse\n",
    "prefix_train = 'TrainFold'\n",
    "prefix_test = 'TestFold'\n",
    "cwd = \"../subjects/min-max/windows_20/tr-False_sliding_1_c-True/folds_intra/\" + 'subject' + str(subject) + '/'\n",
    "\n",
    "spw = 20 # samples per window\n",
    "nmuscles = 12 # initial number of muscles acquired\n",
    "\n",
    "#Enable/Disable shuffle on trainset/testset\n",
    "shuffle_train = False\n",
    "shuffle_test= False\n",
    " \n",
    "#Delete electrogonio signals\n",
    "exclude_features = False\n",
    "#Only use electrogonio signals\n",
    "include_only_features = False\n",
    "#Features to selected/deselected for input to the networks\n",
    "features_select = [1,12] #1 to 4\n",
    "\n",
    "#Select which models to run. Insert comma separated values into 'model_select' var.\n",
    "#List. 0:'FF', 1:'FC2', 2:'FC2DP', 3:'FC3', 4:'FC3dp', 5:'Conv1d', 6:'MultiConv1d' \n",
    "#e.g: model_select = [0,4,6] to select FF,FC3dp,MultiConv1d\n",
    "\n",
    "# Modelli del paper: 11 (FF2), 14 (FF4), 16 (FF5) --> Prova questi!\n",
    "# FF6 per testarlo potente dopo (17)\n",
    "model_lst = ['FF','FC2','FC2DP','FC3','FC3dp','Conv1d','MultiConv1d',\n",
    "             'MultiConv1d_2','MultiConv1d_3', 'MultiConv1d_4', 'MultiConv1d_5', \n",
    "             'FF2', 'CNN1', 'FF3', 'FF4', 'CNN2', 'FF5', 'FF6', 'CNN3', 'CNN1-FF5', 'CNN1-2','CNN1-1', 'CNN1-3', 'CNN_w60']\n",
    "model_select = [11,14,16,17] \n",
    "\n",
    "#Early stop settings\n",
    "maxepoch = 100\n",
    "maxpatience = 10\n",
    "\n",
    "use_cuda = False\n",
    "use_gputil = False\n",
    "cuda_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CUDA\n",
    "\n",
    "if use_gputil and torch.cuda.is_available():\n",
    "    import GPUtil\n",
    "\n",
    "    # Get the first available GPU\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    try:\n",
    "        deviceIDs = GPUtil.getAvailable(order='memory', limit=1, maxLoad=100, maxMemory=20)  # return a list of available gpus\n",
    "    except:\n",
    "        print('GPU not compatible with NVIDIA-SMI')\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(deviceIDs[0])\n",
    "        \n",
    "    ttens = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "    ttens = ttens.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? --> False\n",
      "Cuda Device: cpu\n"
     ]
    }
   ],
   "source": [
    "print('Is CUDA available? --> ' + str(torch.cuda.is_available()))\n",
    "print('Cuda Device: ' + str(cuda_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seeds\n",
    "def setSeeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "setSeeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints header of beautifultable report for each fold\n",
    "def header(model_list,nmodel,nfold,traindataset,testdataset):\n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    print('MODEL: '+model_list[nmodel])\n",
    "    print('Fold: '+str(nfold))\n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++\\n\\n')\n",
    "    shape = list(traindataset.x_data.shape)\n",
    "    print('Trainset fold'+str(i)+' shape: '+str(shape[0])+'x'+str((shape[1]+1)))\n",
    "    shape = list(testdataset.x_data.shape)\n",
    "    print('Testset fold'+str(i)+' shape: '+str(shape[0])+'x'+str((shape[1]+1))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints actual beautifultable for each fold\n",
    "def table(model_list,nmodel,accuracies,precisions,recalls,f1_scores,accuracies_dev):\n",
    "    table = BeautifulTable()\n",
    "    table.column_headers = [\"{}\".format(model_list[nmodel]), \"Avg\", \"Stdev\"]\n",
    "    table.append_row([\"Accuracy\",round(np.average(accuracies),3),round(np.std(accuracies),3)])\n",
    "    table.append_row([\"Precision\",round(np.average(precisions),3),round(np.std(precisions),3)])\n",
    "    table.append_row([\"Recall\",round(np.average(recalls),3),round(np.std(recalls),3)])\n",
    "    table.append_row([\"F1_score\",round(np.average(f1_scores),3),round(np.std(f1_scores),3)])\n",
    "    table.append_row([\"Accuracy_dev\",round(np.average(accuracies_dev),3),round(np.std(accuracies_dev),3)])    \n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saves best model state on disk for each fold\n",
    "def save_checkpoint (state, is_best, filename, logfile):\n",
    "    if is_best:\n",
    "        msg = \"=> Saving a new best. \"+'Epoch: '+str(state['epoch'])\n",
    "        print (msg)\n",
    "        logfile.write(msg + \"\\n\")\n",
    "        torch.save(state, filename)  \n",
    "    else:\n",
    "        msg = \"=> Validation accuracy did not improve. \"+'Epoch: '+str(state['epoch'])\n",
    "        print (msg)\n",
    "        logfile.write(msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute sklearn metrics: Recall, Precision, F1-score\n",
    "def pre_rec (loader, model, positiveLabel):\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate (loader,0):\n",
    "            inputs, labels = data\n",
    "            y_true = np.append(y_true,labels.cpu())\n",
    "            outputs = model(inputs)\n",
    "            outputs[outputs>=0.5] = 1\n",
    "            outputs[outputs<0.5] = 0\n",
    "            y_pred = np.append(y_pred,outputs.cpu())\n",
    "    y_true = np.where(y_true==positiveLabel,0,1)\n",
    "    y_pred = np.where(y_pred==positiveLabel,0,1)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    return round(precision*100,3), round(recall*100,3), round(f1_score*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculates model accuracy. Predicted vs Correct.\n",
    "def accuracy (loader, model):\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs)\n",
    "            outputs[outputs>=0.5] = 1\n",
    "            outputs[outputs<0.5] = 0\n",
    "            total += labels.size(0)\n",
    "            correct += (outputs == labels).sum().item()\n",
    "    return round((100 * correct / total),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Arrays to store metrics\n",
    "accs = np.empty([nfold,1])\n",
    "accs_test_val = np.empty([nfold,1])\n",
    "precisions_0_U = np.empty([nfold,1])\n",
    "recalls_0_U = np.empty([nfold,1])\n",
    "f1_scores_0_U = np.empty([nfold,1])\n",
    "precisions_1_U = np.empty([nfold,1])\n",
    "recalls_1_U = np.empty([nfold,1])\n",
    "f1_scores_1_U = np.empty([nfold,1])\n",
    "precisions_0_L = np.empty([nfold,1])\n",
    "recalls_0_L = np.empty([nfold,1])\n",
    "f1_scores_0_L = np.empty([nfold,1])\n",
    "precisions_1_L = np.empty([nfold,1])\n",
    "recalls_1_L = np.empty([nfold,1])\n",
    "f1_scores_1_L = np.empty([nfold,1])\n",
    "accs_dev = np.empty([nfold,1])\n",
    "times = np.empty([nfold,1])\n",
    "\n",
    "#Calculate avg metrics on folds\n",
    "def averages (vals):\n",
    "    avgs = []\n",
    "    for val in vals:\n",
    "        avgs.append(round(np.average(val),3))\n",
    "    return avgs\n",
    "\n",
    "#Calculate std metrics on folds\n",
    "def stds (vals):\n",
    "    stds = []\n",
    "    for val in vals:\n",
    "        stds.append(round(np.std(val),3))\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle\n",
    "def dev_shuffle (shuffle_train,shuffle_test,val_split,traindataset,testdataset):\n",
    "    train_size = len(traindataset)\n",
    "    test_size = len(testdataset)\n",
    "    train_indices = list(range(train_size))\n",
    "    test_indices = list(range(test_size))\n",
    "    split = int(np.floor(val_split * train_size))\n",
    "    if shuffle_train:\n",
    "        np.random.shuffle(train_indices)\n",
    "    if shuffle_test:\n",
    "        np.random.shuffle(test_indices) \n",
    "    train_indices, dev_indices = train_indices[split:], train_indices[:split]\n",
    "    # Samplers\n",
    "    tr_sampler = SubsetRandomSampler(train_indices)\n",
    "    d_sampler = SubsetRandomSampler(dev_indices)\n",
    "    te_sampler = SubsetRandomSampler(test_indices)\n",
    "    return tr_sampler,d_sampler,te_sampler\n",
    "\n",
    "def data_split (shuffle_train,shuffle_test,val_split,test_val_split,traindataset,testdataset):\n",
    "    train_size = len(traindataset)\n",
    "    test_size = len(testdataset)\n",
    "    train_indices = list(range(train_size))\n",
    "    test_indices = list(range(test_size))\n",
    "    test_val_split = int(np.floor(test_val_split * train_size)) \n",
    "    dev_split = int(np.floor(val_split * (train_size-test_val_split) + test_val_split))\n",
    "    if shuffle_train:\n",
    "        np.random.shuffle(train_indices)\n",
    "    if shuffle_test:\n",
    "        np.random.shuffle(test_indices) \n",
    "    train_indices, dev_indices, test_val_indices = train_indices[dev_split:], train_indices[test_val_split:dev_split], train_indices[:test_val_split]\n",
    "    # Samplers\n",
    "    tr_sampler = SubsetRandomSampler(train_indices)\n",
    "    d_sampler = SubsetRandomSampler(dev_indices)\n",
    "    tv_sampler = SubsetRandomSampler(test_val_indices)                \n",
    "    te_sampler = SubsetRandomSampler(test_indices)\n",
    "    return tr_sampler,d_sampler,tv_sampler,te_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 1\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 2\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 3\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 4\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 5\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 6\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 7\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 8\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 9\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "Loading fold 10\n",
      "Train dataset: 282691 windows;\n",
      "Test dataset (LEARNED): 31410 windows;\n",
      "\n",
      "Each window is composed by 241 samples.\n",
      "The number of muscles is 12\n"
     ]
    }
   ],
   "source": [
    "#Loads and appends all folds all at once\n",
    "trainfolds = []\n",
    "testfolds = []\n",
    "\n",
    "#l=pd.read_csv(cwd +'/list.csv',sep=',',header=None,dtype=np.int32)\n",
    "col_select = np.array([])\n",
    "\n",
    "#This is an hack to test smaller windows\n",
    "for i in range (spw*nmuscles,200):\n",
    "    col_select = np.append(col_select,i)\n",
    "    \n",
    "for i in range (0,spw*nmuscles,nmuscles):\n",
    "    for muscle in features_select:\n",
    "        col_select = np.append(col_select,muscle -1 + i)\n",
    "    cols=np.arange(0,spw*nmuscles+1)\n",
    "\n",
    "if exclude_features & (not include_only_features): #delete gonio\n",
    "    for j in range(fold_offset,fold_offset + nfold):\n",
    "        print(\"Loading fold \" + str(j))\n",
    "        traindata = pd.read_table(os.path.join(cwd, prefix_train + str(j)+'.csv'),sep=',',header=None,dtype=np.float32,usecols=[i for i in cols if i not in col_select.astype(int)])\n",
    "        trainfolds.append(traindata)\n",
    "        testdata = pd.read_table(os.path.join(cwd, prefix_test + str(j)+'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i not in col_select.astype(int)])\n",
    "        testfolds.append(testdata) \n",
    "elif include_only_features & (not exclude_features): #only gonio\n",
    "    for j in range(fold_offset, fold_offset + nfold):\n",
    "        print(\"Loading fold \" + str(j))\n",
    "        traindata = pd.read_table(os.path.join(cwd, prefix_train + str(j)+'.csv'),sep=',',header=None,dtype=np.float32,usecols=[i for i in cols if i in col_select.astype(int)])\n",
    "        testdata = pd.read_table(os.path.join(cwd, prefix_test + str(j)+'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i in col_select.astype(int)])\n",
    "        trainfolds.append(traindata)\n",
    "        testfolds.append(testdata) \n",
    "elif (not include_only_features) & (not exclude_features): \n",
    "    for j in range(fold_offset,fold_offset + nfold):\n",
    "        print(\"Loading fold \" + str(j))\n",
    "        traindata = pd.read_csv(os.path.join(cwd, prefix_train + str(j)+ '.csv'),sep=',',header=None,dtype=np.float32)\n",
    "        testdata = pd.read_csv(os.path.join(cwd, prefix_test + str(j)+'.csv'),sep=',',header=None,dtype=np.float32)\n",
    "        trainfolds.append(traindata)\n",
    "        testfolds.append(testdata)\n",
    "        print('Train dataset: ' + str(len(traindata)) + ' windows;')\n",
    "        print('Test dataset (LEARNED): ' + str(len(testdata)) + ' windows;')\n",
    "else:\n",
    "    raise ValueError('use_gonio and del_gonio cannot be both True')\n",
    "\n",
    "\n",
    "nmuscles=int((len(traindata.columns)-1)/spw)\n",
    "print('\\nEach window is composed by ' + str(len(traindata.columns)) + ' samples.')\n",
    "print('The number of muscles is ' + str(nmuscles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmuscles=int((len(traindata.columns)-1)/spw) #used for layer dimensions and stride CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models\n",
    "from models import *\n",
    "models._spw = spw\n",
    "models._nmuscles = nmuscles\n",
    "models._batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(models._nmuscles)\n",
    "\n",
    "#import models\n",
    "#from models import *\n",
    "#TEST DIMENSIONS\n",
    "#models.nmuscles = nmuscles\n",
    "def testdimensions():\n",
    "    model = Model23()\n",
    "    print(model)\n",
    "    x = torch.randn(32,1,480)\n",
    "    model.test_dim(x)\n",
    " \n",
    "#testdimensions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldnames = ['Fold','Acc_L', 'Acc_U',\n",
    "              'R_0_U','R_1_U',\n",
    "              'R_0_L','R_1_L',\n",
    "              'Stop_epoch','Accuracy_dev'] #coloumn names report FOLD CSV\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#TRAINING LOOP\n",
    "def train_test():\n",
    "    for k in model_select:\n",
    "        \n",
    "        table = BeautifulTable()\n",
    "        avgtable = BeautifulTable()\n",
    "        fieldnames1 = [model_lst[k],'Avg','Std_dev'] #column names report GLOBAL CSV\n",
    "        folder = os.path.join(cwd,'Report_'+str(model_lst[k]))\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "        logfilepath = os.path.join(folder,'log.txt')\n",
    "        logfile = open(logfilepath,\"w\") \n",
    "\n",
    "        with open(os.path.join(folder,'Report_folds.csv'),'w') as f_fold, open(os.path.join(folder,'Report_global.csv'),'w') as f_global:\n",
    "            writer = csv.DictWriter(f_fold, fieldnames = fieldnames)\n",
    "            writer1  = csv.DictWriter(f_global, fieldnames = fieldnames1)\n",
    "            writer.writeheader()\n",
    "            writer1.writeheader()\n",
    "            t0 = 0\n",
    "            t1 = 0\n",
    "            for i in range(1,nfold+1):\n",
    "                \n",
    "                t0 = time.time()\n",
    "                setSeeds(0)\n",
    "                \n",
    "                class Traindataset(Dataset):\n",
    "                    def __init__(self):\n",
    "                        self.data=trainfolds[i-1]\n",
    "                        self.x_data=torch.from_numpy(np.asarray(self.data.iloc[:, 0:-1])) \n",
    "                        self.len=self.data.shape[0]\n",
    "                        self.y_data = torch.from_numpy(np.asarray(self.data.iloc[:, [-1]]))\n",
    "                        if (use_cuda):\n",
    "                            self.x_data = self.x_data.cuda()\n",
    "                            self.y_data = self.y_data.cuda()\n",
    "                    def __getitem__(self, index):\n",
    "                        return self.x_data[index], self.y_data[index]\n",
    "                    def __len__(self):\n",
    "                        return self.len\n",
    "                class Testdataset(Dataset):\n",
    "                    def __init__(self):\n",
    "                        self.data=testfolds[i-1]\n",
    "                        self.x_data=torch.from_numpy(np.asarray(self.data.iloc[:, 0:-1]))\n",
    "                        self.len=self.data.shape[0]\n",
    "                        self.y_data = torch.from_numpy(np.asarray(self.data.iloc[:, [-1]]))\n",
    "                        if (use_cuda):\n",
    "                            self.x_data = self.x_data.cuda()\n",
    "                            self.y_data = self.y_data.cuda()\n",
    "                    def __getitem__(self, index):\n",
    "                        return self.x_data[index], self.y_data[index]\n",
    "                    def __len__(self):\n",
    "                        return self.len\n",
    "\n",
    "                traindataset = Traindataset()\n",
    "                testdataset = Testdataset()\n",
    "\n",
    "                header(model_lst,k,i,traindataset,testdataset)\n",
    "\n",
    "                #train_sampler,dev_sampler,test_sampler=dev_shuffle(shuffle_train,shuffle_test,val_split,traindataset,testdataset)\n",
    "                train_sampler,dev_sampler,test_val_sampler,test_sampler=data_split(shuffle_train,shuffle_test,val_split,test_val_split,traindataset,testdataset)\n",
    "                #loaders\n",
    "                train_loader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size, \n",
    "                                                           sampler=train_sampler,drop_last=True)\n",
    "                test_val_loader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size,\n",
    "                                                                sampler=test_val_sampler,drop_last=True)\n",
    "                dev_loader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size, \n",
    "                                                           sampler=dev_sampler,drop_last=True)\n",
    "                test_loader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size,\n",
    "                                                                sampler=test_sampler,drop_last=True)\n",
    "                modelClass = \"Model\" + str(k)\n",
    "                model = eval(modelClass)()\n",
    "                \n",
    "                if (use_cuda):\n",
    "                    model = model.cuda()\n",
    "\n",
    "                if doTrain:\n",
    "                    \n",
    "                    # criterion = nn.BCELoss(size_average=True)\n",
    "                    criterion = nn.BCELoss(reduction = 'mean')    # Cambiato perché dava un warning (size_average era un vecchio metodo in Pytorch)\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr)    \n",
    "                    msg = 'Accuracy on test set before training: '+ str(accuracy(test_loader, model)) +'\\n'\n",
    "                    print(msg)\n",
    "                    logfile.write(msg + \"\\n\")\n",
    "                    #EARLY STOP\n",
    "                    epoch = 0\n",
    "                    patience = 0\n",
    "                    best_acc_dev=0\n",
    "                    while (epoch<maxepoch and patience < maxpatience):\n",
    "                        running_loss = 0.0\n",
    "                        for l, data in enumerate(train_loader, 0):\n",
    "                            inputs, labels = data\n",
    "                            if use_cuda:\n",
    "                                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                            inputs, labels = Variable(inputs), Variable(labels)\n",
    "                            y_pred = model(inputs)\n",
    "                            if use_cuda:\n",
    "                                y_pred = y_pred.cuda()\n",
    "                            loss = criterion(y_pred, labels)\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            running_loss += loss.item()\n",
    "                            #print accuracy ever l mini-batches\n",
    "                            if l % 2000 == 1999:\n",
    "                                msg = '[%d, %5d] loss: %.3f' %(epoch + 1, l + 1, running_loss / 999)\n",
    "                                print(msg)\n",
    "                                logfile.write(msg + \"\\n\")\n",
    "                                running_loss = 0.0\n",
    "                                #msg = 'Accuracy on dev set:' + str(accuracy(dev_loader))\n",
    "                                #print(msg)\n",
    "                                #logfile.write(msg + \"\\n\")        \n",
    "                        accdev = (accuracy(dev_loader, model))\n",
    "                        msg = 'Accuracy on dev set:' + str(accdev)\n",
    "                        print(msg)\n",
    "                        logfile.write(msg + \"\\n\")        \n",
    "                        is_best = bool(accdev > best_acc_dev)\n",
    "                        best_acc_dev = (max(accdev, best_acc_dev))\n",
    "                        save_checkpoint({\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'best_acc_dev': best_acc_dev\n",
    "                        }, is_best,os.path.join(folder,'F'+str(i)+'best.pth.tar'), logfile)\n",
    "                        if is_best:\n",
    "                            patience=0\n",
    "                        else:\n",
    "                            patience = patience+1\n",
    "                        epoch = epoch+1\n",
    "                        logfile.flush()\n",
    "                   #Devo capire cosa inserire qua dentro per far sì che mi carichi tre set! \n",
    "                if doEval:\n",
    "                    if use_cuda:                        \n",
    "                        state = torch.load(os.path.join(folder,'F'+str(i)+'best.pth.tar'))\n",
    "                    else:\n",
    "                        state = torch.load(os.path.join(folder,'F'+str(i)+'best.pth.tar'), map_location=lambda storage, loc: storage)\n",
    "                    stop_epoch = state['epoch']\n",
    "                    model.load_state_dict(state['state_dict'])\n",
    "                    if not use_cuda:\n",
    "                        model.cpu()\n",
    "                    accuracy_dev = state['best_acc_dev']\n",
    "                    model.eval()\n",
    "                    acctest = (accuracy(test_loader, model))\n",
    "                    acctest_val = (accuracy(test_val_loader, model))\n",
    "                    accs[i-1] = acctest\n",
    "                    accs_test_val[i-1] = acctest_val\n",
    "                    \n",
    "                    precision_0_U,recall_0_U,f1_score_0_U = pre_rec(test_loader, model, 0.0)\n",
    "                    precisions_0_U[i-1] = precision_0_U\n",
    "                    recalls_0_U[i-1] = recall_0_U\n",
    "                    f1_scores_0_U[i-1] = f1_score_0_U\n",
    "                    \n",
    "                    precision_1_U,recall_1_U,f1_score_1_U = pre_rec(test_loader, model, 1.0)\n",
    "                    precisions_1_U[i-1] = precision_1_U\n",
    "                    recalls_1_U[i-1] = recall_1_U\n",
    "                    f1_scores_1_U[i-1] = f1_score_1_U\n",
    "                    \n",
    "                    precision_0_L,recall_0_L,f1_score_0_L = pre_rec(test_val_loader, model, 0.0)\n",
    "                    precisions_0_L[i-1] = precision_0_L\n",
    "                    recalls_0_L[i-1] = recall_0_L\n",
    "                    f1_scores_0_L[i-1] = f1_score_0_L\n",
    "                    \n",
    "                    precision_1_L,recall_1_L,f1_score_1_L = pre_rec(test_val_loader, model, 1.0)\n",
    "                    precisions_1_L[i-1] = precision_1_L\n",
    "                    recalls_1_L[i-1] = recall_1_L\n",
    "                    f1_scores_1_L[i-1] = f1_score_1_L\n",
    "                    \n",
    "                    accs_dev[i-1] = accuracy_dev\n",
    "                    \n",
    "                    writer.writerow({'Fold': i,'Acc_L': acctest_val, 'Acc_U': acctest,\n",
    "                                     #'P_0_U': precision_0_U,'R_0_U': recall_0_U,'F1_0_U': f1_score_0_U,\n",
    "                                     'R_0_U': recall_0_U,\n",
    "                                     #'P_1_U': precision_1_U,'R_1_U': recall_1_U,'F1_1_U': f1_score_1_U,\n",
    "                                     'R_1_U': recall_1_U,\n",
    "                                     #'P_0_L': precision_0_L,'R_0_L': recall_0_L,'F1_0_L': f1_score_0_L,\n",
    "                                     'R_0_L': recall_0_L,\n",
    "                                     #'P_1_L': precision_1_L,'R_1_L': recall_1_L,'F1_1_L': f1_score_1_L,\n",
    "                                     'R_1_L': recall_1_L,\n",
    "                                     'Stop_epoch': stop_epoch,'Accuracy_dev': accuracy_dev})\n",
    "                    table.column_headers = fieldnames\n",
    "                    table.append_row([i,acctest_val,acctest,\n",
    "                                      #precision_0_U,recall_0_U,f1_score_0_U,\n",
    "                                      recall_0_U,\n",
    "                                      #precision_1_U,recall_1_U,f1_score_1_U,\n",
    "                                      recall_1_U,\n",
    "                                      #precision_0_L,recall_0_L,f1_score_0_L,\n",
    "                                      recall_0_L,\n",
    "                                      #precision_1_L,recall_1_L,f1_score_1_L,\n",
    "                                      recall_1_L,\n",
    "                                      stop_epoch,accuracy_dev])\n",
    "                    print(table)\n",
    "                    print('----------------------------------------------------------------------')\n",
    "                    logfile.write(str(table) + \"\\n----------------------------------------------------------------------\\n\")\n",
    "                    t1 = time.time()\n",
    "                    times[i-1] = int(t1-t0)\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=np.sum(times)))\n",
    "            writer.writerow({})\n",
    "            writer.writerow({'Fold': 'Elapsed time: '+duration})\n",
    "            avg_acc_test_val = round(np.average(accs_test_val),3)\n",
    "            std_acc_test_val = round(np.std(accs_test_val),3)\n",
    "            \n",
    "            avg_acc_test_val,avg_a,avg_p_0_U,avg_r_0_U,avg_f_0_U,avg_p_1_U,avg_r_1_U,avg_f_1_U,avg_p_0_L,avg_r_0_L,avg_f_0_L,avg_p_1_L,avg_r_1_L,avg_f_1_L,avg_a_d=averages([accs_test_val,accs,precisions_0_U,recalls_0_U,f1_scores_0_U,precisions_1_U,recalls_1_U,f1_scores_1_U,precisions_0_L,recalls_0_L,f1_scores_0_L,precisions_1_L,recalls_1_L,f1_scores_1_L,accs_dev])\n",
    "            std_acc_test_val,std_a,std_p_0_U,std_r_0_U,std_f_0_U,std_p_1_U,std_r_1_U,std_f_1_U,std_p_0_L,std_r_0_L,std_f_0_L,std_p_1_L,std_r_1_L,std_f_1_L,std_a_d=stds([accs_test_val,accs,precisions_0_U,recalls_0_U,f1_scores_0_U,precisions_1_U,recalls_1_U,f1_scores_1_U,precisions_0_L,recalls_0_L,f1_scores_0_L,precisions_1_L,recalls_1_L,f1_scores_1_L,accs_dev])\n",
    "            \n",
    "            writer1.writerow({model_lst[k]: 'Acc_U','Avg': avg_a,'Std_dev': std_acc_test_val})\n",
    "            writer1.writerow({model_lst[k]: 'Acc_L','Avg': avg_acc_test_val,'Std_dev': std_a})\n",
    "            writer1.writerow({model_lst[k]: 'P_0_U','Avg': avg_p_0_U ,'Std_dev': std_p_0_U})\n",
    "            writer1.writerow({model_lst[k]: 'R_0_U','Avg': avg_r_0_U,'Std_dev': std_r_0_U})\n",
    "            writer1.writerow({model_lst[k]: 'F1_0_U','Avg': avg_f_0_U,'Std_dev': std_f_0_U})\n",
    "            writer1.writerow({model_lst[k]: 'P_1_U','Avg': avg_p_1_U,'Std_dev': std_p_1_U})\n",
    "            writer1.writerow({model_lst[k]: 'R_1_U','Avg': avg_r_1_U,'Std_dev': std_r_1_U})\n",
    "            writer1.writerow({model_lst[k]: 'F1_1_U','Avg': avg_f_1_U,'Std_dev': std_f_1_U})            \n",
    "            writer1.writerow({model_lst[k]: 'P_0_L','Avg': avg_p_0_L,'Std_dev': std_p_0_L})\n",
    "            writer1.writerow({model_lst[k]: 'R_0_L','Avg': avg_r_0_L,'Std_dev': std_r_0_L})\n",
    "            writer1.writerow({model_lst[k]: 'F1_0_L','Avg': avg_f_0_L,'Std_dev': std_f_0_L})\n",
    "            writer1.writerow({model_lst[k]: 'P_1_L','Avg': avg_p_1_L,'Std_dev': std_p_1_L})\n",
    "            writer1.writerow({model_lst[k]: 'R_1_L','Avg': avg_r_1_L,'Std_dev': std_r_1_L})\n",
    "            writer1.writerow({model_lst[k]: 'F1_1_L','Avg': avg_f_1_L,'Std_dev': std_f_1_L})                        \n",
    "            writer1.writerow({model_lst[k]: 'Acc_dev','Avg': avg_a_d,'Std_dev': std_a_d})\n",
    "            writer1.writerow({})\n",
    "            writer1.writerow({model_lst[k]: 'Elapsed time: '+duration})\n",
    "            avgtable.column_headers = fieldnames1\n",
    "            avgtable.append_row(['Acc_U',avg_a,std_a])\n",
    "            avgtable.append_row(['Acc_L',avg_acc_test_val,std_acc_test_val])\n",
    "            avgtable.append_row(['P_0_U',avg_p_0_U,std_p_0_U])\n",
    "            avgtable.append_row(['R_0_U',avg_r_0_U,std_r_0_U])\n",
    "            avgtable.append_row(['F1_0_U',avg_f_0_U,std_f_0_U])\n",
    "            avgtable.append_row(['P_1_U',avg_p_1_U,std_p_1_U])\n",
    "            avgtable.append_row(['R_1_U',avg_r_1_U,std_r_1_U])\n",
    "            avgtable.append_row(['F1_1_U',avg_f_1_U,std_f_1_U])                        \n",
    "            avgtable.append_row(['P_0_L',avg_p_0_L,std_p_0_L])\n",
    "            avgtable.append_row(['R_0_L',avg_r_0_L,std_r_0_L])\n",
    "            avgtable.append_row(['F1_0_L',avg_f_0_L,std_f_0_L])\n",
    "            avgtable.append_row(['P_1_L',avg_p_1_L,std_p_1_L])\n",
    "            avgtable.append_row(['R_1_L',avg_r_1_L,std_r_1_L])\n",
    "            avgtable.append_row(['F1_1_L',avg_f_1_L,std_f_1_L])            \n",
    "            avgtable.append_row(['Accuracy_dev',avg_a_d,std_a_d])\n",
    "            print(avgtable)\n",
    "            logfile.write(str(avgtable) + \"\\n\")\n",
    "            msg = 'Elapsed time: '+ duration + '\\n\\n'\n",
    "            print(msg)\n",
    "            logfile.write(msg )\n",
    "\n",
    "        logfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am NOT using CUDA: SUCCESS!\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 49.726\n",
      "\n",
      "[1,  2000] loss: 0.689\n",
      "[1,  4000] loss: 0.501\n",
      "[1,  6000] loss: 0.476\n",
      "Accuracy on dev set:89.32\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.458\n",
      "[2,  4000] loss: 0.454\n",
      "[2,  6000] loss: 0.440\n",
      "Accuracy on dev set:89.646\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.427\n",
      "[3,  4000] loss: 0.427\n",
      "[3,  6000] loss: 0.416\n",
      "Accuracy on dev set:89.807\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.408\n",
      "[4,  4000] loss: 0.408\n",
      "[4,  6000] loss: 0.405\n",
      "Accuracy on dev set:89.855\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.393\n",
      "[5,  4000] loss: 0.395\n",
      "[5,  6000] loss: 0.394\n",
      "Accuracy on dev set:90.086\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.387\n",
      "[6,  4000] loss: 0.384\n",
      "[6,  6000] loss: 0.383\n",
      "Accuracy on dev set:90.071\n",
      "=> Validation accuracy did not improve. Epoch: 6\n",
      "[7,  2000] loss: 0.377\n",
      "[7,  4000] loss: 0.378\n",
      "[7,  6000] loss: 0.379\n",
      "Accuracy on dev set:90.063\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.369\n",
      "[8,  4000] loss: 0.377\n",
      "[8,  6000] loss: 0.367\n",
      "Accuracy on dev set:90.346\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.366\n",
      "[9,  4000] loss: 0.365\n",
      "[9,  6000] loss: 0.371\n",
      "Accuracy on dev set:90.362\n",
      "=> Saving a new best. Epoch: 9\n",
      "[10,  2000] loss: 0.357\n",
      "[10,  4000] loss: 0.367\n",
      "[10,  6000] loss: 0.359\n",
      "Accuracy on dev set:90.409\n",
      "=> Saving a new best. Epoch: 10\n",
      "[11,  2000] loss: 0.355\n",
      "[11,  4000] loss: 0.359\n",
      "[11,  6000] loss: 0.353\n",
      "Accuracy on dev set:90.444\n",
      "=> Saving a new best. Epoch: 11\n",
      "[12,  2000] loss: 0.347\n",
      "[12,  4000] loss: 0.358\n",
      "[12,  6000] loss: 0.350\n",
      "Accuracy on dev set:90.318\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.345\n",
      "[13,  4000] loss: 0.350\n",
      "[13,  6000] loss: 0.347\n",
      "Accuracy on dev set:90.35\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.346\n",
      "[14,  4000] loss: 0.338\n",
      "[14,  6000] loss: 0.341\n",
      "Accuracy on dev set:90.299\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.342\n",
      "[15,  4000] loss: 0.334\n",
      "[15,  6000] loss: 0.338\n",
      "Accuracy on dev set:90.161\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.336\n",
      "[16,  4000] loss: 0.330\n",
      "[16,  6000] loss: 0.332\n",
      "Accuracy on dev set:90.185\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.327\n",
      "[17,  4000] loss: 0.331\n",
      "[17,  6000] loss: 0.329\n",
      "Accuracy on dev set:90.157\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.317\n",
      "[18,  4000] loss: 0.327\n",
      "[18,  6000] loss: 0.324\n",
      "Accuracy on dev set:90.102\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.319\n",
      "[19,  4000] loss: 0.319\n",
      "[19,  6000] loss: 0.311\n",
      "Accuracy on dev set:90.02\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.311\n",
      "[20,  4000] loss: 0.312\n",
      "[20,  6000] loss: 0.310\n",
      "Accuracy on dev set:90.122\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.305\n",
      "[21,  4000] loss: 0.306\n",
      "[21,  6000] loss: 0.304\n",
      "Accuracy on dev set:90.075\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 2\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 45.865\n",
      "\n",
      "[1,  2000] loss: 0.689\n",
      "[1,  4000] loss: 0.501\n",
      "[1,  6000] loss: 0.476\n",
      "Accuracy on dev set:89.454\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.458\n",
      "[2,  4000] loss: 0.454\n",
      "[2,  6000] loss: 0.440\n",
      "Accuracy on dev set:89.906\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.427\n",
      "[3,  4000] loss: 0.427\n",
      "[3,  6000] loss: 0.416\n",
      "Accuracy on dev set:90.165\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.408\n",
      "[4,  4000] loss: 0.408\n",
      "[4,  6000] loss: 0.405\n",
      "Accuracy on dev set:90.267\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.393\n",
      "[5,  4000] loss: 0.395\n",
      "[5,  6000] loss: 0.394\n",
      "Accuracy on dev set:90.487\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.387\n",
      "[6,  4000] loss: 0.384\n",
      "[6,  6000] loss: 0.383\n",
      "Accuracy on dev set:90.464\n",
      "=> Validation accuracy did not improve. Epoch: 6\n",
      "[7,  2000] loss: 0.377\n",
      "[7,  4000] loss: 0.378\n",
      "[7,  6000] loss: 0.379\n",
      "Accuracy on dev set:90.401\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.369\n",
      "[8,  4000] loss: 0.377\n",
      "[8,  6000] loss: 0.367\n",
      "Accuracy on dev set:90.692\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.366\n",
      "[9,  4000] loss: 0.365\n",
      "[9,  6000] loss: 0.371\n",
      "Accuracy on dev set:90.676\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.357\n",
      "[10,  4000] loss: 0.367\n",
      "[10,  6000] loss: 0.359\n",
      "Accuracy on dev set:90.645\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.355\n",
      "[11,  4000] loss: 0.359\n",
      "[11,  6000] loss: 0.353\n",
      "Accuracy on dev set:90.731\n",
      "=> Saving a new best. Epoch: 11\n",
      "[12,  2000] loss: 0.347\n",
      "[12,  4000] loss: 0.358\n",
      "[12,  6000] loss: 0.350\n",
      "Accuracy on dev set:90.472\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.345\n",
      "[13,  4000] loss: 0.350\n",
      "[13,  6000] loss: 0.347\n",
      "Accuracy on dev set:90.554\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.346\n",
      "[14,  4000] loss: 0.338\n",
      "[14,  6000] loss: 0.341\n",
      "Accuracy on dev set:90.452\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.342\n",
      "[15,  4000] loss: 0.334\n",
      "[15,  6000] loss: 0.338\n",
      "Accuracy on dev set:90.338\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.336\n",
      "[16,  4000] loss: 0.330\n",
      "[16,  6000] loss: 0.332\n",
      "Accuracy on dev set:90.436\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.327\n",
      "[17,  4000] loss: 0.331\n",
      "[17,  6000] loss: 0.329\n",
      "Accuracy on dev set:90.436\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.317\n",
      "[18,  4000] loss: 0.327\n",
      "[18,  6000] loss: 0.324\n",
      "Accuracy on dev set:90.354\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.319\n",
      "[19,  4000] loss: 0.319\n",
      "[19,  6000] loss: 0.311\n",
      "Accuracy on dev set:90.126\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.311\n",
      "[20,  4000] loss: 0.312\n",
      "[20,  6000] loss: 0.310\n",
      "Accuracy on dev set:90.377\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.305\n",
      "[21,  4000] loss: 0.306\n",
      "[21,  6000] loss: 0.304\n",
      "Accuracy on dev set:90.283\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 3\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 48.108\n",
      "\n",
      "[1,  2000] loss: 0.682\n",
      "[1,  4000] loss: 0.494\n",
      "[1,  6000] loss: 0.470\n",
      "Accuracy on dev set:88.762\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.452\n",
      "[2,  4000] loss: 0.446\n",
      "[2,  6000] loss: 0.429\n",
      "Accuracy on dev set:89.049\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.418\n",
      "[3,  4000] loss: 0.417\n",
      "[3,  6000] loss: 0.407\n",
      "Accuracy on dev set:89.273\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.398\n",
      "[4,  4000] loss: 0.396\n",
      "[4,  6000] loss: 0.392\n",
      "Accuracy on dev set:89.54\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.381\n",
      "[5,  4000] loss: 0.382\n",
      "[5,  6000] loss: 0.382\n",
      "Accuracy on dev set:89.591\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.374\n",
      "[6,  4000] loss: 0.371\n",
      "[6,  6000] loss: 0.370\n",
      "Accuracy on dev set:89.662\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.364\n",
      "[7,  4000] loss: 0.364\n",
      "[7,  6000] loss: 0.364\n",
      "Accuracy on dev set:89.689\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.355\n",
      "[8,  4000] loss: 0.365\n",
      "[8,  6000] loss: 0.350\n",
      "Accuracy on dev set:89.752\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.351\n",
      "[9,  4000] loss: 0.349\n",
      "[9,  6000] loss: 0.357\n",
      "Accuracy on dev set:89.788\n",
      "=> Saving a new best. Epoch: 9\n",
      "[10,  2000] loss: 0.342\n",
      "[10,  4000] loss: 0.351\n",
      "[10,  6000] loss: 0.343\n",
      "Accuracy on dev set:89.741\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.338\n",
      "[11,  4000] loss: 0.344\n",
      "[11,  6000] loss: 0.338\n",
      "Accuracy on dev set:89.729\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.332\n",
      "[12,  4000] loss: 0.341\n",
      "[12,  6000] loss: 0.335\n",
      "Accuracy on dev set:89.595\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.330\n",
      "[13,  4000] loss: 0.332\n",
      "[13,  6000] loss: 0.329\n",
      "Accuracy on dev set:89.642\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.328\n",
      "[14,  4000] loss: 0.321\n",
      "[14,  6000] loss: 0.324\n",
      "Accuracy on dev set:89.458\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.325\n",
      "[15,  4000] loss: 0.317\n",
      "[15,  6000] loss: 0.319\n",
      "Accuracy on dev set:89.45\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.319\n",
      "[16,  4000] loss: 0.311\n",
      "[16,  6000] loss: 0.315\n",
      "Accuracy on dev set:89.556\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.309\n",
      "[17,  4000] loss: 0.314\n",
      "[17,  6000] loss: 0.311\n",
      "Accuracy on dev set:89.509\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.301\n",
      "[18,  4000] loss: 0.309\n",
      "[18,  6000] loss: 0.307\n",
      "Accuracy on dev set:89.45\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.302\n",
      "[19,  4000] loss: 0.301\n",
      "[19,  6000] loss: 0.296\n",
      "Accuracy on dev set:89.061\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 4\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 48.066\n",
      "\n",
      "[1,  2000] loss: 0.679\n",
      "[1,  4000] loss: 0.485\n",
      "[1,  6000] loss: 0.454\n",
      "Accuracy on dev set:88.966\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.439\n",
      "[2,  4000] loss: 0.431\n",
      "[2,  6000] loss: 0.422\n",
      "Accuracy on dev set:89.147\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.406\n",
      "[3,  4000] loss: 0.408\n",
      "[3,  6000] loss: 0.401\n",
      "Accuracy on dev set:89.363\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.392\n",
      "[4,  4000] loss: 0.388\n",
      "[4,  6000] loss: 0.388\n",
      "Accuracy on dev set:89.627\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.376\n",
      "[5,  4000] loss: 0.377\n",
      "[5,  6000] loss: 0.378\n",
      "Accuracy on dev set:89.627\n",
      "=> Validation accuracy did not improve. Epoch: 5\n",
      "[6,  2000] loss: 0.371\n",
      "[6,  4000] loss: 0.368\n",
      "[6,  6000] loss: 0.369\n",
      "Accuracy on dev set:89.768\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.366\n",
      "[7,  4000] loss: 0.360\n",
      "[7,  6000] loss: 0.361\n",
      "Accuracy on dev set:89.8\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.357\n",
      "[8,  4000] loss: 0.360\n",
      "[8,  6000] loss: 0.350\n",
      "Accuracy on dev set:89.823\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.350\n",
      "[9,  4000] loss: 0.347\n",
      "[9,  6000] loss: 0.358\n",
      "Accuracy on dev set:89.815\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.346\n",
      "[10,  4000] loss: 0.348\n",
      "[10,  6000] loss: 0.344\n",
      "Accuracy on dev set:89.654\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.340\n",
      "[11,  4000] loss: 0.345\n",
      "[11,  6000] loss: 0.340\n",
      "Accuracy on dev set:89.772\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.338\n",
      "[12,  4000] loss: 0.341\n",
      "[12,  6000] loss: 0.339\n",
      "Accuracy on dev set:89.367\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.336\n",
      "[13,  4000] loss: 0.336\n",
      "[13,  6000] loss: 0.334\n",
      "Accuracy on dev set:89.548\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.334\n",
      "[14,  4000] loss: 0.325\n",
      "[14,  6000] loss: 0.330\n",
      "Accuracy on dev set:89.281\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.330\n",
      "[15,  4000] loss: 0.323\n",
      "[15,  6000] loss: 0.331\n",
      "Accuracy on dev set:89.638\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.324\n",
      "[16,  4000] loss: 0.326\n",
      "[16,  6000] loss: 0.325\n",
      "Accuracy on dev set:89.674\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.321\n",
      "[17,  4000] loss: 0.323\n",
      "[17,  6000] loss: 0.323\n",
      "Accuracy on dev set:89.811\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.316\n",
      "[18,  4000] loss: 0.320\n",
      "[18,  6000] loss: 0.322\n",
      "Accuracy on dev set:89.772\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 5\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 48.388\n",
      "\n",
      "[1,  2000] loss: 0.697\n",
      "[1,  4000] loss: 0.516\n",
      "[1,  6000] loss: 0.487\n",
      "Accuracy on dev set:89.084\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.476\n",
      "[2,  4000] loss: 0.463\n",
      "[2,  6000] loss: 0.452\n",
      "Accuracy on dev set:89.182\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.438\n",
      "[3,  4000] loss: 0.441\n",
      "[3,  6000] loss: 0.431\n",
      "Accuracy on dev set:89.371\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.423\n",
      "[4,  4000] loss: 0.419\n",
      "[4,  6000] loss: 0.418\n",
      "Accuracy on dev set:89.619\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.402\n",
      "[5,  4000] loss: 0.410\n",
      "[5,  6000] loss: 0.410\n",
      "Accuracy on dev set:89.615\n",
      "=> Validation accuracy did not improve. Epoch: 5\n",
      "[6,  2000] loss: 0.402\n",
      "[6,  4000] loss: 0.396\n",
      "[6,  6000] loss: 0.399\n",
      "Accuracy on dev set:89.713\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.393\n",
      "[7,  4000] loss: 0.387\n",
      "[7,  6000] loss: 0.390\n",
      "Accuracy on dev set:89.65\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.387\n",
      "[8,  4000] loss: 0.384\n",
      "[8,  6000] loss: 0.378\n",
      "Accuracy on dev set:89.752\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.375\n",
      "[9,  4000] loss: 0.374\n",
      "[9,  6000] loss: 0.382\n",
      "Accuracy on dev set:89.748\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.370\n",
      "[10,  4000] loss: 0.376\n",
      "[10,  6000] loss: 0.366\n",
      "Accuracy on dev set:89.709\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.363\n",
      "[11,  4000] loss: 0.370\n",
      "[11,  6000] loss: 0.365\n",
      "Accuracy on dev set:89.752\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.358\n",
      "[12,  4000] loss: 0.364\n",
      "[12,  6000] loss: 0.362\n",
      "Accuracy on dev set:89.67\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.351\n",
      "[13,  4000] loss: 0.358\n",
      "[13,  6000] loss: 0.357\n",
      "Accuracy on dev set:89.623\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.353\n",
      "[14,  4000] loss: 0.347\n",
      "[14,  6000] loss: 0.350\n",
      "Accuracy on dev set:89.517\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.348\n",
      "[15,  4000] loss: 0.343\n",
      "[15,  6000] loss: 0.351\n",
      "Accuracy on dev set:89.697\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.342\n",
      "[16,  4000] loss: 0.343\n",
      "[16,  6000] loss: 0.342\n",
      "Accuracy on dev set:89.701\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.339\n",
      "[17,  4000] loss: 0.339\n",
      "[17,  6000] loss: 0.339\n",
      "Accuracy on dev set:89.619\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.332\n",
      "[18,  4000] loss: 0.336\n",
      "[18,  6000] loss: 0.336\n",
      "Accuracy on dev set:89.666\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.28 | 93.44 | 90.85 | 94.90 | 94.10 | 85.75 |    8     |   89.752   |\n",
      "|      |   6   |   4   |   7   |   6   |   4   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 6\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 40.265\n",
      "\n",
      "[1,  2000] loss: 0.686\n",
      "[1,  4000] loss: 0.503\n",
      "[1,  6000] loss: 0.478\n",
      "Accuracy on dev set:88.337\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.468\n",
      "[2,  4000] loss: 0.453\n",
      "[2,  6000] loss: 0.443\n",
      "Accuracy on dev set:89.013\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.430\n",
      "[3,  4000] loss: 0.434\n",
      "[3,  6000] loss: 0.423\n",
      "Accuracy on dev set:89.218\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.413\n",
      "[4,  4000] loss: 0.413\n",
      "[4,  6000] loss: 0.407\n",
      "Accuracy on dev set:89.351\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.392\n",
      "[5,  4000] loss: 0.402\n",
      "[5,  6000] loss: 0.398\n",
      "Accuracy on dev set:89.477\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.390\n",
      "[6,  4000] loss: 0.387\n",
      "[6,  6000] loss: 0.387\n",
      "Accuracy on dev set:89.654\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.384\n",
      "[7,  4000] loss: 0.378\n",
      "[7,  6000] loss: 0.379\n",
      "Accuracy on dev set:89.693\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.375\n",
      "[8,  4000] loss: 0.377\n",
      "[8,  6000] loss: 0.372\n",
      "Accuracy on dev set:89.725\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.367\n",
      "[9,  4000] loss: 0.367\n",
      "[9,  6000] loss: 0.373\n",
      "Accuracy on dev set:89.744\n",
      "=> Saving a new best. Epoch: 9\n",
      "[10,  2000] loss: 0.364\n",
      "[10,  4000] loss: 0.370\n",
      "[10,  6000] loss: 0.361\n",
      "Accuracy on dev set:89.713\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.359\n",
      "[11,  4000] loss: 0.363\n",
      "[11,  6000] loss: 0.360\n",
      "Accuracy on dev set:89.713\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.352\n",
      "[12,  4000] loss: 0.360\n",
      "[12,  6000] loss: 0.357\n",
      "Accuracy on dev set:89.489\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.347\n",
      "[13,  4000] loss: 0.354\n",
      "[13,  6000] loss: 0.352\n",
      "Accuracy on dev set:89.473\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.349\n",
      "[14,  4000] loss: 0.343\n",
      "[14,  6000] loss: 0.348\n",
      "Accuracy on dev set:89.395\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.343\n",
      "[15,  4000] loss: 0.340\n",
      "[15,  6000] loss: 0.346\n",
      "Accuracy on dev set:89.548\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.338\n",
      "[16,  4000] loss: 0.341\n",
      "[16,  6000] loss: 0.338\n",
      "Accuracy on dev set:89.528\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.336\n",
      "[17,  4000] loss: 0.335\n",
      "[17,  6000] loss: 0.335\n",
      "Accuracy on dev set:89.379\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.331\n",
      "[18,  4000] loss: 0.334\n",
      "[18,  6000] loss: 0.333\n",
      "Accuracy on dev set:89.383\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.327\n",
      "[19,  4000] loss: 0.324\n",
      "[19,  6000] loss: 0.323\n",
      "Accuracy on dev set:89.312\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.28 | 93.44 | 90.85 | 94.90 | 94.10 | 85.75 |    8     |   89.752   |\n",
      "|      |   6   |   4   |   7   |   6   |   4   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  6   | 88.10 | 92.73 | 91.41 | 93.63 | 93.81 | 85.62 |    9     |   89.744   |\n",
      "|      |   9   |   7   |   1   |   1   |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 7\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 43.103\n",
      "\n",
      "[1,  2000] loss: 0.678\n",
      "[1,  4000] loss: 0.499\n",
      "[1,  6000] loss: 0.477\n",
      "Accuracy on dev set:89.139\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.464\n",
      "[2,  4000] loss: 0.448\n",
      "[2,  6000] loss: 0.438\n",
      "Accuracy on dev set:89.281\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.426\n",
      "[3,  4000] loss: 0.427\n",
      "[3,  6000] loss: 0.418\n",
      "Accuracy on dev set:89.414\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.410\n",
      "[4,  4000] loss: 0.409\n",
      "[4,  6000] loss: 0.405\n",
      "Accuracy on dev set:89.583\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.393\n",
      "[5,  4000] loss: 0.401\n",
      "[5,  6000] loss: 0.399\n",
      "Accuracy on dev set:89.638\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.391\n",
      "[6,  4000] loss: 0.387\n",
      "[6,  6000] loss: 0.390\n",
      "Accuracy on dev set:89.764\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.386\n",
      "[7,  4000] loss: 0.379\n",
      "[7,  6000] loss: 0.382\n",
      "Accuracy on dev set:89.803\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.381\n",
      "[8,  4000] loss: 0.379\n",
      "[8,  6000] loss: 0.373\n",
      "Accuracy on dev set:89.87\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.372\n",
      "[9,  4000] loss: 0.371\n",
      "[9,  6000] loss: 0.375\n",
      "Accuracy on dev set:89.914\n",
      "=> Saving a new best. Epoch: 9\n",
      "[10,  2000] loss: 0.369\n",
      "[10,  4000] loss: 0.371\n",
      "[10,  6000] loss: 0.364\n",
      "Accuracy on dev set:89.8\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.361\n",
      "[11,  4000] loss: 0.365\n",
      "[11,  6000] loss: 0.365\n",
      "Accuracy on dev set:89.788\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.355\n",
      "[12,  4000] loss: 0.362\n",
      "[12,  6000] loss: 0.359\n",
      "Accuracy on dev set:89.552\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.353\n",
      "[13,  4000] loss: 0.356\n",
      "[13,  6000] loss: 0.354\n",
      "Accuracy on dev set:89.505\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.354\n",
      "[14,  4000] loss: 0.345\n",
      "[14,  6000] loss: 0.350\n",
      "Accuracy on dev set:89.689\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.345\n",
      "[15,  4000] loss: 0.348\n",
      "[15,  6000] loss: 0.350\n",
      "Accuracy on dev set:89.772\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.341\n",
      "[16,  4000] loss: 0.342\n",
      "[16,  6000] loss: 0.343\n",
      "Accuracy on dev set:89.835\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.339\n",
      "[17,  4000] loss: 0.337\n",
      "[17,  6000] loss: 0.341\n",
      "Accuracy on dev set:89.78\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.338\n",
      "[18,  4000] loss: 0.334\n",
      "[18,  6000] loss: 0.334\n",
      "Accuracy on dev set:89.725\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.329\n",
      "[19,  4000] loss: 0.326\n",
      "[19,  6000] loss: 0.327\n",
      "Accuracy on dev set:89.603\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.28 | 93.44 | 90.85 | 94.90 | 94.10 | 85.75 |    8     |   89.752   |\n",
      "|      |   6   |   4   |   7   |   6   |   4   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  6   | 88.10 | 92.73 | 91.41 | 93.63 | 93.81 | 85.62 |    9     |   89.744   |\n",
      "|      |   9   |   7   |   1   |   1   |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  7   | 88.08 | 91.38 | 92.46 | 90.67 | 94.29 | 85.38 |    9     |   89.914   |\n",
      "|      |   4   |   6   |   2   |   7   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 8\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 40.453\n",
      "\n",
      "[1,  2000] loss: 0.697\n",
      "[1,  4000] loss: 0.521\n",
      "[1,  6000] loss: 0.498\n",
      "Accuracy on dev set:88.947\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.486\n",
      "[2,  4000] loss: 0.469\n",
      "[2,  6000] loss: 0.462\n",
      "Accuracy on dev set:89.182\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.452\n",
      "[3,  4000] loss: 0.450\n",
      "[3,  6000] loss: 0.441\n",
      "Accuracy on dev set:89.257\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.433\n",
      "[4,  4000] loss: 0.437\n",
      "[4,  6000] loss: 0.426\n",
      "Accuracy on dev set:89.517\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.416\n",
      "[5,  4000] loss: 0.420\n",
      "[5,  6000] loss: 0.424\n",
      "Accuracy on dev set:89.603\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.412\n",
      "[6,  4000] loss: 0.411\n",
      "[6,  6000] loss: 0.412\n",
      "Accuracy on dev set:89.772\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.407\n",
      "[7,  4000] loss: 0.399\n",
      "[7,  6000] loss: 0.403\n",
      "Accuracy on dev set:89.803\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.403\n",
      "[8,  4000] loss: 0.399\n",
      "[8,  6000] loss: 0.395\n",
      "Accuracy on dev set:89.847\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.392\n",
      "[9,  4000] loss: 0.397\n",
      "[9,  6000] loss: 0.396\n",
      "Accuracy on dev set:89.906\n",
      "=> Saving a new best. Epoch: 9\n",
      "[10,  2000] loss: 0.392\n",
      "[10,  4000] loss: 0.391\n",
      "[10,  6000] loss: 0.387\n",
      "Accuracy on dev set:89.819\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.384\n",
      "[11,  4000] loss: 0.389\n",
      "[11,  6000] loss: 0.386\n",
      "Accuracy on dev set:89.792\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.378\n",
      "[12,  4000] loss: 0.384\n",
      "[12,  6000] loss: 0.381\n",
      "Accuracy on dev set:89.737\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.374\n",
      "[13,  4000] loss: 0.380\n",
      "[13,  6000] loss: 0.378\n",
      "Accuracy on dev set:89.733\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.376\n",
      "[14,  4000] loss: 0.369\n",
      "[14,  6000] loss: 0.372\n",
      "Accuracy on dev set:89.827\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.366\n",
      "[15,  4000] loss: 0.372\n",
      "[15,  6000] loss: 0.372\n",
      "Accuracy on dev set:89.961\n",
      "=> Saving a new best. Epoch: 15\n",
      "[16,  2000] loss: 0.362\n",
      "[16,  4000] loss: 0.366\n",
      "[16,  6000] loss: 0.364\n",
      "Accuracy on dev set:89.965\n",
      "=> Saving a new best. Epoch: 16\n",
      "[17,  2000] loss: 0.362\n",
      "[17,  4000] loss: 0.359\n",
      "[17,  6000] loss: 0.364\n",
      "Accuracy on dev set:89.972\n",
      "=> Saving a new best. Epoch: 17\n",
      "[18,  2000] loss: 0.360\n",
      "[18,  4000] loss: 0.355\n",
      "[18,  6000] loss: 0.359\n",
      "Accuracy on dev set:89.992\n",
      "=> Saving a new best. Epoch: 18\n",
      "[19,  2000] loss: 0.351\n",
      "[19,  4000] loss: 0.349\n",
      "[19,  6000] loss: 0.351\n",
      "Accuracy on dev set:89.768\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.348\n",
      "[20,  4000] loss: 0.344\n",
      "[20,  6000] loss: 0.343\n",
      "Accuracy on dev set:90.039\n",
      "=> Saving a new best. Epoch: 20\n",
      "[21,  2000] loss: 0.342\n",
      "[21,  4000] loss: 0.343\n",
      "[21,  6000] loss: 0.339\n",
      "Accuracy on dev set:90.028\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.342\n",
      "[22,  4000] loss: 0.333\n",
      "[22,  6000] loss: 0.331\n",
      "Accuracy on dev set:89.89\n",
      "=> Validation accuracy did not improve. Epoch: 22\n",
      "[23,  2000] loss: 0.326\n",
      "[23,  4000] loss: 0.330\n",
      "[23,  6000] loss: 0.329\n",
      "Accuracy on dev set:89.631\n",
      "=> Validation accuracy did not improve. Epoch: 23\n",
      "[24,  2000] loss: 0.332\n",
      "[24,  4000] loss: 0.328\n",
      "[24,  6000] loss: 0.319\n",
      "Accuracy on dev set:89.658\n",
      "=> Validation accuracy did not improve. Epoch: 24\n",
      "[25,  2000] loss: 0.328\n",
      "[25,  4000] loss: 0.321\n",
      "[25,  6000] loss: 0.312\n",
      "Accuracy on dev set:89.19\n",
      "=> Validation accuracy did not improve. Epoch: 25\n",
      "[26,  2000] loss: 0.316\n",
      "[26,  4000] loss: 0.315\n",
      "[26,  6000] loss: 0.315\n",
      "Accuracy on dev set:89.422\n",
      "=> Validation accuracy did not improve. Epoch: 26\n",
      "[27,  2000] loss: 0.311\n",
      "[27,  4000] loss: 0.312\n",
      "[27,  6000] loss: 0.309\n",
      "Accuracy on dev set:88.998\n",
      "=> Validation accuracy did not improve. Epoch: 27\n",
      "[28,  2000] loss: 0.304\n",
      "[28,  4000] loss: 0.307\n",
      "[28,  6000] loss: 0.305\n",
      "Accuracy on dev set:88.927\n",
      "=> Validation accuracy did not improve. Epoch: 28\n",
      "[29,  2000] loss: 0.302\n",
      "[29,  4000] loss: 0.299\n",
      "[29,  6000] loss: 0.299\n",
      "Accuracy on dev set:88.998\n",
      "=> Validation accuracy did not improve. Epoch: 29\n",
      "[30,  2000] loss: 0.293\n",
      "[30,  4000] loss: 0.297\n",
      "[30,  6000] loss: 0.295\n",
      "Accuracy on dev set:88.475\n",
      "=> Validation accuracy did not improve. Epoch: 30\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.28 | 93.44 | 90.85 | 94.90 | 94.10 | 85.75 |    8     |   89.752   |\n",
      "|      |   6   |   4   |   7   |   6   |   4   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  6   | 88.10 | 92.73 | 91.41 | 93.63 | 93.81 | 85.62 |    9     |   89.744   |\n",
      "|      |   9   |   7   |   1   |   1   |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  7   | 88.08 | 91.38 | 92.46 | 90.67 | 94.29 | 85.38 |    9     |   89.914   |\n",
      "|      |   4   |   6   |   2   |   7   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  8   | 87.92 | 96.73 | 93.77 | 98.98 | 94.34 | 85.11 |    20    |   90.039   |\n",
      "|      |   5   |   2   |   7   |   4   |   7   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 9\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 38.746\n",
      "\n",
      "[1,  2000] loss: 0.696\n",
      "[1,  4000] loss: 0.518\n",
      "[1,  6000] loss: 0.496\n",
      "Accuracy on dev set:89.116\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.482\n",
      "[2,  4000] loss: 0.466\n",
      "[2,  6000] loss: 0.458\n",
      "Accuracy on dev set:89.159\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.449\n",
      "[3,  4000] loss: 0.443\n",
      "[3,  6000] loss: 0.435\n",
      "Accuracy on dev set:89.32\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.425\n",
      "[4,  4000] loss: 0.428\n",
      "[4,  6000] loss: 0.420\n",
      "Accuracy on dev set:89.552\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.410\n",
      "[5,  4000] loss: 0.412\n",
      "[5,  6000] loss: 0.417\n",
      "Accuracy on dev set:89.65\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.404\n",
      "[6,  4000] loss: 0.402\n",
      "[6,  6000] loss: 0.405\n",
      "Accuracy on dev set:89.591\n",
      "=> Validation accuracy did not improve. Epoch: 6\n",
      "[7,  2000] loss: 0.399\n",
      "[7,  4000] loss: 0.392\n",
      "[7,  6000] loss: 0.394\n",
      "Accuracy on dev set:89.631\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.395\n",
      "[8,  4000] loss: 0.391\n",
      "[8,  6000] loss: 0.387\n",
      "Accuracy on dev set:89.674\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.384\n",
      "[9,  4000] loss: 0.386\n",
      "[9,  6000] loss: 0.387\n",
      "Accuracy on dev set:89.65\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.383\n",
      "[10,  4000] loss: 0.382\n",
      "[10,  6000] loss: 0.376\n",
      "Accuracy on dev set:89.465\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.372\n",
      "[11,  4000] loss: 0.380\n",
      "[11,  6000] loss: 0.377\n",
      "Accuracy on dev set:89.292\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.369\n",
      "[12,  4000] loss: 0.373\n",
      "[12,  6000] loss: 0.372\n",
      "Accuracy on dev set:89.3\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.363\n",
      "[13,  4000] loss: 0.372\n",
      "[13,  6000] loss: 0.366\n",
      "Accuracy on dev set:89.43\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.365\n",
      "[14,  4000] loss: 0.360\n",
      "[14,  6000] loss: 0.361\n",
      "Accuracy on dev set:89.438\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.355\n",
      "[15,  4000] loss: 0.361\n",
      "[15,  6000] loss: 0.361\n",
      "Accuracy on dev set:89.556\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.352\n",
      "[16,  4000] loss: 0.357\n",
      "[16,  6000] loss: 0.352\n",
      "Accuracy on dev set:89.654\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.350\n",
      "[17,  4000] loss: 0.349\n",
      "[17,  6000] loss: 0.353\n",
      "Accuracy on dev set:89.784\n",
      "=> Saving a new best. Epoch: 17\n",
      "[18,  2000] loss: 0.350\n",
      "[18,  4000] loss: 0.344\n",
      "[18,  6000] loss: 0.345\n",
      "Accuracy on dev set:89.623\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.339\n",
      "[19,  4000] loss: 0.339\n",
      "[19,  6000] loss: 0.340\n",
      "Accuracy on dev set:89.505\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.337\n",
      "[20,  4000] loss: 0.334\n",
      "[20,  6000] loss: 0.334\n",
      "Accuracy on dev set:89.599\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.333\n",
      "[21,  4000] loss: 0.333\n",
      "[21,  6000] loss: 0.330\n",
      "Accuracy on dev set:89.721\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.331\n",
      "[22,  4000] loss: 0.328\n",
      "[22,  6000] loss: 0.322\n",
      "Accuracy on dev set:89.513\n",
      "=> Validation accuracy did not improve. Epoch: 22\n",
      "[23,  2000] loss: 0.318\n",
      "[23,  4000] loss: 0.323\n",
      "[23,  6000] loss: 0.321\n",
      "Accuracy on dev set:89.465\n",
      "=> Validation accuracy did not improve. Epoch: 23\n",
      "[24,  2000] loss: 0.325\n",
      "[24,  4000] loss: 0.319\n",
      "[24,  6000] loss: 0.314\n",
      "Accuracy on dev set:89.524\n",
      "=> Validation accuracy did not improve. Epoch: 24\n",
      "[25,  2000] loss: 0.322\n",
      "[25,  4000] loss: 0.314\n",
      "[25,  6000] loss: 0.304\n",
      "Accuracy on dev set:89.505\n",
      "=> Validation accuracy did not improve. Epoch: 25\n",
      "[26,  2000] loss: 0.308\n",
      "[26,  4000] loss: 0.309\n",
      "[26,  6000] loss: 0.309\n",
      "Accuracy on dev set:89.367\n",
      "=> Validation accuracy did not improve. Epoch: 26\n",
      "[27,  2000] loss: 0.304\n",
      "[27,  4000] loss: 0.306\n",
      "[27,  6000] loss: 0.303\n",
      "Accuracy on dev set:89.08\n",
      "=> Validation accuracy did not improve. Epoch: 27\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.28 | 93.44 | 90.85 | 94.90 | 94.10 | 85.75 |    8     |   89.752   |\n",
      "|      |   6   |   4   |   7   |   6   |   4   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  6   | 88.10 | 92.73 | 91.41 | 93.63 | 93.81 | 85.62 |    9     |   89.744   |\n",
      "|      |   9   |   7   |   1   |   1   |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  7   | 88.08 | 91.38 | 92.46 | 90.67 | 94.29 | 85.38 |    9     |   89.914   |\n",
      "|      |   4   |   6   |   2   |   7   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  8   | 87.92 | 96.73 | 93.77 | 98.98 | 94.34 | 85.11 |    20    |   90.039   |\n",
      "|      |   5   |   2   |   7   |   4   |   7   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  9   | 88.06 | 94.35 | 95.65 | 93.49 | 93.62 | 85.64 |    17    |   89.784   |\n",
      "|      |   3   |   2   |   9   |   7   |   6   |   1   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF2\n",
      "Fold: 10\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 60.971\n",
      "\n",
      "[1,  2000] loss: 0.677\n",
      "[1,  4000] loss: 0.483\n",
      "[1,  6000] loss: 0.465\n",
      "Accuracy on dev set:89.123\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.449\n",
      "[2,  4000] loss: 0.430\n",
      "[2,  6000] loss: 0.423\n",
      "Accuracy on dev set:89.178\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.414\n",
      "[3,  4000] loss: 0.407\n",
      "[3,  6000] loss: 0.401\n",
      "Accuracy on dev set:89.277\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.392\n",
      "[4,  4000] loss: 0.397\n",
      "[4,  6000] loss: 0.386\n",
      "Accuracy on dev set:89.548\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.376\n",
      "[5,  4000] loss: 0.381\n",
      "[5,  6000] loss: 0.383\n",
      "Accuracy on dev set:89.662\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.375\n",
      "[6,  4000] loss: 0.368\n",
      "[6,  6000] loss: 0.372\n",
      "Accuracy on dev set:89.701\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.367\n",
      "[7,  4000] loss: 0.362\n",
      "[7,  6000] loss: 0.361\n",
      "Accuracy on dev set:89.748\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.364\n",
      "[8,  4000] loss: 0.361\n",
      "[8,  6000] loss: 0.354\n",
      "Accuracy on dev set:89.831\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.353\n",
      "[9,  4000] loss: 0.353\n",
      "[9,  6000] loss: 0.353\n",
      "Accuracy on dev set:89.807\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.351\n",
      "[10,  4000] loss: 0.349\n",
      "[10,  6000] loss: 0.344\n",
      "Accuracy on dev set:89.855\n",
      "=> Saving a new best. Epoch: 10\n",
      "[11,  2000] loss: 0.341\n",
      "[11,  4000] loss: 0.345\n",
      "[11,  6000] loss: 0.343\n",
      "Accuracy on dev set:89.548\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.334\n",
      "[12,  4000] loss: 0.340\n",
      "[12,  6000] loss: 0.337\n",
      "Accuracy on dev set:89.721\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.329\n",
      "[13,  4000] loss: 0.336\n",
      "[13,  6000] loss: 0.328\n",
      "Accuracy on dev set:89.709\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.328\n",
      "[14,  4000] loss: 0.328\n",
      "[14,  6000] loss: 0.324\n",
      "Accuracy on dev set:89.803\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.319\n",
      "[15,  4000] loss: 0.325\n",
      "[15,  6000] loss: 0.325\n",
      "Accuracy on dev set:89.756\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.315\n",
      "[16,  4000] loss: 0.320\n",
      "[16,  6000] loss: 0.316\n",
      "Accuracy on dev set:89.827\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.314\n",
      "[17,  4000] loss: 0.309\n",
      "[17,  6000] loss: 0.316\n",
      "Accuracy on dev set:89.882\n",
      "=> Saving a new best. Epoch: 17\n",
      "[18,  2000] loss: 0.313\n",
      "[18,  4000] loss: 0.306\n",
      "[18,  6000] loss: 0.307\n",
      "Accuracy on dev set:89.65\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.302\n",
      "[19,  4000] loss: 0.301\n",
      "[19,  6000] loss: 0.303\n",
      "Accuracy on dev set:89.634\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.301\n",
      "[20,  4000] loss: 0.297\n",
      "[20,  6000] loss: 0.293\n",
      "Accuracy on dev set:89.564\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.294\n",
      "[21,  4000] loss: 0.294\n",
      "[21,  6000] loss: 0.291\n",
      "Accuracy on dev set:89.575\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.289\n",
      "[22,  4000] loss: 0.289\n",
      "[22,  6000] loss: 0.283\n",
      "Accuracy on dev set:89.351\n",
      "=> Validation accuracy did not improve. Epoch: 22\n",
      "[23,  2000] loss: 0.279\n",
      "[23,  4000] loss: 0.284\n",
      "[23,  6000] loss: 0.283\n",
      "Accuracy on dev set:88.903\n",
      "=> Validation accuracy did not improve. Epoch: 23\n",
      "[24,  2000] loss: 0.283\n",
      "[24,  4000] loss: 0.278\n",
      "[24,  6000] loss: 0.278\n",
      "Accuracy on dev set:89.057\n",
      "=> Validation accuracy did not improve. Epoch: 24\n",
      "[25,  2000] loss: 0.280\n",
      "[25,  4000] loss: 0.276\n",
      "[25,  6000] loss: 0.266\n",
      "Accuracy on dev set:88.935\n",
      "=> Validation accuracy did not improve. Epoch: 25\n",
      "[26,  2000] loss: 0.269\n",
      "[26,  4000] loss: 0.270\n",
      "[26,  6000] loss: 0.272\n",
      "Accuracy on dev set:88.84\n",
      "=> Validation accuracy did not improve. Epoch: 26\n",
      "[27,  2000] loss: 0.263\n",
      "[27,  4000] loss: 0.268\n",
      "[27,  6000] loss: 0.268\n",
      "Accuracy on dev set:88.534\n",
      "=> Validation accuracy did not improve. Epoch: 27\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 89.98 | 89.12 | 94.25 | 86.80 | 95.09 | 87.02 |    11    |   90.444   |\n",
      "|      |   1   |   5   |   9   |   1   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 88.10 | 90.58 | 94.52 | 88.28 | 93.86 | 85.59 |    11    |   90.731   |\n",
      "|      |   9   |       |       |   2   |   9   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 88.02 | 89.39 | 94.30 | 86.86 | 94.23 | 85.31 |    9     |   89.788   |\n",
      "|      |   4   |   5   |   6   |   4   |   2   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 87.98 | 89.10 | 93.61 | 86.55 | 93.88 | 85.41 |    8     |   89.823   |\n",
      "|      |   1   |   9   |   9   |       |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.28 | 93.44 | 90.85 | 94.90 | 94.10 | 85.75 |    8     |   89.752   |\n",
      "|      |   6   |   4   |   7   |   6   |   4   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  6   | 88.10 | 92.73 | 91.41 | 93.63 | 93.81 | 85.62 |    9     |   89.744   |\n",
      "|      |   9   |   7   |   1   |   1   |   3   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  7   | 88.08 | 91.38 | 92.46 | 90.67 | 94.29 | 85.38 |    9     |   89.914   |\n",
      "|      |   4   |   6   |   2   |   7   |       |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  8   | 87.92 | 96.73 | 93.77 | 98.98 | 94.34 | 85.11 |    20    |   90.039   |\n",
      "|      |   5   |   2   |   7   |   4   |   7   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  9   | 88.06 | 94.35 | 95.65 | 93.49 | 93.62 | 85.64 |    17    |   89.784   |\n",
      "|      |   3   |   2   |   9   |   7   |   6   |   1   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  10  | 87.88 | 90.17 | 91.17 | 89.83 | 93.41 | 85.47 |    17    |   89.882   |\n",
      "|      |   6   |   9   |   9   |       |   6   |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+--------------+--------+---------+\n",
      "|     FF2      |  Avg   | Std_dev |\n",
      "+--------------+--------+---------+\n",
      "|    Acc_U     | 91.704 |  2.425  |\n",
      "+--------------+--------+---------+\n",
      "|    Acc_L     | 88.245 |  0.588  |\n",
      "+--------------+--------+---------+\n",
      "|    P_0_U     | 85.043 |  7.181  |\n",
      "+--------------+--------+---------+\n",
      "|    R_0_U     | 93.205 |  1.548  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_0_U    | 88.77  |  3.91   |\n",
      "+--------------+--------+---------+\n",
      "|    P_1_U     | 95.944 |  0.987  |\n",
      "+--------------+--------+---------+\n",
      "|    R_1_U     | 91.002 |  3.944  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_1_U    | 93.351 |  1.848  |\n",
      "+--------------+--------+---------+\n",
      "|    P_0_L     | 74.537 |  2.111  |\n",
      "+--------------+--------+---------+\n",
      "|    R_0_L     | 94.067 |  0.443  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_0_L    | 83.158 |  1.417  |\n",
      "+--------------+--------+---------+\n",
      "|    P_1_L     | 96.993 |  0.142  |\n",
      "+--------------+--------+---------+\n",
      "|    R_1_L     | 85.634 |  0.495  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_1_L    | 90.96  |  0.254  |\n",
      "+--------------+--------+---------+\n",
      "| Accuracy_dev | 89.99  |  0.317  |\n",
      "+--------------+--------+---------+\n",
      "Elapsed time: 0:44:35\n",
      "\n",
      "\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF4\n",
      "Fold: 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 282691x241\n",
      "Testset fold228 shape: 31410x241\n",
      "\n",
      "Accuracy on test set before training: 31.132\n",
      "\n",
      "[1,  2000] loss: 0.721\n",
      "[1,  4000] loss: 0.470\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-64327027fd8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'I am NOT using CUDA: SUCCESS!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-393d10558a67>\u001b[0m in \u001b[0;36mtrain_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m                             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nmuscles=int((len(traindata.columns)-1)/spw)\n",
    "if use_cuda and not use_gputil and cuda_device!=None and torch.cuda.is_available():\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        print('I am using CUDA: SUCCESS!')\n",
    "        train_test()\n",
    "else:\n",
    "    print('I am NOT using CUDA: SUCCESS!')\n",
    "    train_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
