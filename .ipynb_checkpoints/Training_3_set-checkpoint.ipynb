{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Import libraries\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from torch import backends\n",
    "from beautifultable import BeautifulTable\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##SETTINGS\n",
    "doTrain = True\n",
    "doEval = True\n",
    "\n",
    "nfold = 5 #number of folds to train\n",
    "fold_offset = 1\n",
    "lr=0.01 #learning rate\n",
    "\n",
    "batch_size = 32\n",
    "val_split = 0.2 #trainset percentage allocated for devset\n",
    "test_val_split = 0.1 #trainset percentage allocated for test_val set (i.e. the test set of known patients)\n",
    "\n",
    "#cwd = os.getcwd()\n",
    "cwd = \"../subjects/min-max/windows_20/tr-True_sliding_20_c-False/folds_test\"\n",
    "subject = 1 # serve per caricare le folds da cartelle diverse\n",
    "prefix_train = 'TrainFold'\n",
    "prefix_test = 'TestFold'\n",
    "\n",
    "spw=20 #samples per window\n",
    "nmuscles=12 #initial number of muscles acquired\n",
    "\n",
    "#Enable/Disable shuffle on trainset/testset\n",
    "shuffle_train = False\n",
    "shuffle_test= False\n",
    "\n",
    "#Delete electrogonio signals\n",
    "# 3 = Left Rectus Femuris; 5 = Left Goniometer; 9 = Right Rectus Femuris; 11 = Right Goniometer\n",
    "exclude_features = True\n",
    "#Only use electrogonio signals\n",
    "include_only_features = False\n",
    "#Features to selected/deselected for input to the networks\n",
    "features_select = [3,5,9,11] #1 to 4\n",
    "\n",
    "#Select which models to run. Insert comma separated values into 'model_select' var.\n",
    "#List. 0:'FF', 1:'FC2', 2:'FC2DP', 3:'FC3', 4:'FC3dp', 5:'Conv1d', 6:'MultiConv1d' \n",
    "#e.g: model_select = [0,4,6] to select FF,FC3dp,MultiConv1d\n",
    "\n",
    "# Modelli del paper: 11 (FF2), 14 (FF4), 16 (FF5) --> Prova questi!\n",
    "# FF6 per testarlo potente dopo (17)\n",
    "model_lst = ['FF','FC2','FC2DP','FC3','FC3dp','Conv1d','MultiConv1d',\n",
    "             'MultiConv1d_2','MultiConv1d_3', 'MultiConv1d_4', 'MultiConv1d_5', \n",
    "             'FF2', 'CNN1', 'FF3', 'FF4', 'CNN2', 'FF5', 'FF6', 'CNN3', 'CNN1-FF5', 'CNN1-2','CNN1-1', 'CNN1-3', 'CNN_w60']\n",
    "model_select = [14] \n",
    "\n",
    "#Early stop settings\n",
    "maxepoch = 100\n",
    "maxpatience = 10\n",
    "\n",
    "use_cuda = False\n",
    "use_gputil = False\n",
    "cuda_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CUDA\n",
    "\n",
    "if use_gputil and torch.cuda.is_available():\n",
    "    import GPUtil\n",
    "\n",
    "    # Get the first available GPU\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    try:\n",
    "        deviceIDs = GPUtil.getAvailable(order='memory', limit=1, maxLoad=100, maxMemory=20)  # return a list of available gpus\n",
    "    except:\n",
    "        print('GPU not compatible with NVIDIA-SMI')\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(deviceIDs[0])\n",
    "        \n",
    "    ttens = torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "    ttens = ttens.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available? --> False\n",
      "Cuda Device: cpu\n"
     ]
    }
   ],
   "source": [
    "print('Is CUDA available? --> ' + str(torch.cuda.is_available()))\n",
    "print('Cuda Device: ' + str(cuda_device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seeds\n",
    "def setSeeds(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "setSeeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints header of beautifultable report for each fold\n",
    "def header(model_list,nmodel,nfold,traindataset,testdataset, testdataset_U):\n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    print('MODEL: '+model_list[nmodel])\n",
    "    print('Fold: '+str(nfold))\n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++\\n\\n')\n",
    "    shape = list(traindataset.x_data.shape)\n",
    "    print('Trainset fold'+str(i)+' shape: '+str(shape[0])+'x'+str((shape[1]+1)))\n",
    "    shape = list(testdataset.x_data.shape)\n",
    "    print('Testset (L) fold'+str(i)+' shape: '+str(shape[0])+'x'+str((shape[1]+1)))\n",
    "    shape = list(testdataset_U.x_data.shape)\n",
    "    print('Testset (U) fold' + str(i) + ' shape: ' + str(shape[0])+ 'x' + str((shape[1]+1)) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prints actual beautifultable for each fold\n",
    "def table(model_list,nmodel,accuracies,precisions,recalls,f1_scores,accuracies_dev):\n",
    "    table = BeautifulTable()\n",
    "    table.column_headers = [\"{}\".format(model_list[nmodel]), \"Avg\", \"Stdev\"]\n",
    "    table.append_row([\"Accuracy\",round(np.average(accuracies),3),round(np.std(accuracies),3)])\n",
    "    table.append_row([\"Precision\",round(np.average(precisions),3),round(np.std(precisions),3)])\n",
    "    table.append_row([\"Recall\",round(np.average(recalls),3),round(np.std(recalls),3)])\n",
    "    table.append_row([\"F1_score\",round(np.average(f1_scores),3),round(np.std(f1_scores),3)])\n",
    "    table.append_row([\"Accuracy_dev\",round(np.average(accuracies_dev),3),round(np.std(accuracies_dev),3)])    \n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Saves best model state on disk for each fold\n",
    "def save_checkpoint (state, is_best, filename, logfile):\n",
    "    if is_best:\n",
    "        msg = \"=> Saving a new best. \"+'Epoch: '+str(state['epoch'])\n",
    "        print (msg)\n",
    "        logfile.write(msg + \"\\n\")\n",
    "        torch.save(state, filename)  \n",
    "    else:\n",
    "        msg = \"=> Validation accuracy did not improve. \"+'Epoch: '+str(state['epoch'])\n",
    "        print (msg)\n",
    "        logfile.write(msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compute sklearn metrics: Recall, Precision, F1-score\n",
    "def pre_rec (loader, model, positiveLabel):\n",
    "    y_true = np.array([])\n",
    "    y_pred = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate (loader,0):\n",
    "            inputs, labels = data\n",
    "            y_true = np.append(y_true,labels.cpu())\n",
    "            outputs = model(inputs)\n",
    "            outputs[outputs>=0.5] = 1\n",
    "            outputs[outputs<0.5] = 0\n",
    "            y_pred = np.append(y_pred,outputs.cpu())\n",
    "    y_true = np.where(y_true==positiveLabel,0,1)\n",
    "    y_pred = np.where(y_pred==positiveLabel,0,1)\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "    return round(precision*100,3), round(recall*100,3), round(f1_score*100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculates model accuracy. Predicted vs Correct.\n",
    "def accuracy (loader, model):\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader, 0):\n",
    "            inputs, labels = data    # Carica i dati\n",
    "            outputs = model(inputs)    # Tira fuori gli output\n",
    "            outputs[outputs>=0.5] = 1    # Se l'output è >= 0.5 --> outputs[i] = 1\n",
    "            outputs[outputs<0.5] = 0    # Se l'output è < 0.5 --> outputs[i] = 0\n",
    "            total += labels.size(0)     # Calcola i labels totali\n",
    "            correct += (outputs == labels).sum().item()    # Conta i corretti (quelli che matchano)\n",
    "    return round((100 * correct / total),3)    # Tira fuori la percentuale di accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Arrays to store metrics\n",
    "accs = np.empty([nfold,1])\n",
    "accs_test_val = np.empty([nfold,1])\n",
    "precisions_0_U = np.empty([nfold,1])\n",
    "recalls_0_U = np.empty([nfold,1])\n",
    "f1_scores_0_U = np.empty([nfold,1])\n",
    "precisions_1_U = np.empty([nfold,1])\n",
    "recalls_1_U = np.empty([nfold,1])\n",
    "f1_scores_1_U = np.empty([nfold,1])\n",
    "precisions_0_L = np.empty([nfold,1])\n",
    "recalls_0_L = np.empty([nfold,1])\n",
    "f1_scores_0_L = np.empty([nfold,1])\n",
    "precisions_1_L = np.empty([nfold,1])\n",
    "recalls_1_L = np.empty([nfold,1])\n",
    "f1_scores_1_L = np.empty([nfold,1])\n",
    "accs_dev = np.empty([nfold,1])\n",
    "times = np.empty([nfold,1])\n",
    "\n",
    "#Calculate avg metrics on folds\n",
    "def averages (vals):\n",
    "    avgs = []\n",
    "    for val in vals:\n",
    "        avgs.append(round(np.average(val),3))\n",
    "    return avgs\n",
    "\n",
    "#Calculate std metrics on folds\n",
    "def stds (vals):\n",
    "    stds = []\n",
    "    for val in vals:\n",
    "        stds.append(round(np.std(val),3))\n",
    "    return stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Shuffle\n",
    "def dev_shuffle (shuffle_train,shuffle_test,val_split,traindataset,testdataset):\n",
    "    train_size = len(traindataset)\n",
    "    test_size = len(testdataset)\n",
    "    train_indices = list(range(train_size))\n",
    "    test_indices = list(range(test_size))\n",
    "    split = int(np.floor(val_split * train_size))\n",
    "    if shuffle_train:\n",
    "        np.random.shuffle(train_indices)\n",
    "    if shuffle_test:\n",
    "        np.random.shuffle(test_indices) \n",
    "    train_indices, dev_indices = train_indices[split:], train_indices[:split]\n",
    "    # Samplers\n",
    "    tr_sampler = SubsetRandomSampler(train_indices)\n",
    "    d_sampler = SubsetRandomSampler(dev_indices)\n",
    "    te_sampler = SubsetRandomSampler(test_indices)\n",
    "    return tr_sampler,d_sampler,te_sampler\n",
    "\n",
    "# Questa funzione serve dividere i vari set una volta caricate le fold\n",
    "# In particolare, verrà usata solo per 'dev_loader', dato che lo split \n",
    "# nei vari set è già stato fatto quando sono state create le fold\n",
    "def data_split (shuffle_train,shuffle_test,val_split,test_val_split,traindataset,testdataset):\n",
    "    train_size = len(traindataset)\n",
    "    test_size = len(testdataset)\n",
    "    train_indices = list(range(train_size))\n",
    "    test_indices = list(range(test_size))\n",
    "    test_val_split = int(np.floor(test_val_split * train_size)) \n",
    "    dev_split = int(np.floor(val_split * (train_size-test_val_split) + test_val_split))\n",
    "    if shuffle_train:\n",
    "        np.random.shuffle(train_indices)\n",
    "    if shuffle_test:\n",
    "        np.random.shuffle(test_indices) \n",
    "    train_indices, dev_indices, test_val_indices = train_indices[dev_split:], train_indices[test_val_split:dev_split], train_indices[:test_val_split]\n",
    "    # Samplers\n",
    "    tr_sampler = SubsetRandomSampler(train_indices)\n",
    "    d_sampler = SubsetRandomSampler(dev_indices)\n",
    "    tv_sampler = SubsetRandomSampler(test_val_indices)                \n",
    "    te_sampler = SubsetRandomSampler(test_indices)\n",
    "    return tr_sampler,d_sampler,tv_sampler,te_sampler\n",
    "\n",
    "# Questa funzione serve se usiamo come input della rete 3 files:\n",
    "    # TRAINFOLD\n",
    "    # TESTFOLD_LEARNED\n",
    "    # TESTFOLD_UNLEARNED\n",
    "# L'unico file che deve essere effettivamente suddiviso, in questo caso, è il TRAINFOLD, dato che useremo\n",
    "# una percentuale 'val_split' (hyperparameter) per il validation, e una percentuale 1-'val_split'\n",
    "# per il vero e proprio training della rete.\n",
    "# La funzione da in output i sampler da utilizzare come parametri per il DataLoader:\n",
    "    # train_sampler\n",
    "    # dev_sampler\n",
    "def split_train ( val_split, traindataset ): \n",
    "    train_size = len(traindataset)    # lunghezza del TRAIN_DATASET\n",
    "    train_indices = list(range(train_size))    # crea una lista che va da 0 -> lunghezza di train_size totale\n",
    "    dev_size = int(np.floor(val_split * train_size))    # Dimensione del dev_set\n",
    "    split = int(np.floor((train_size - dev_size)))    # Valore di split dei 2 set\n",
    "\n",
    "    train_indices_bis, dev_indices = train_indices[:split], train_indices[split:]    # Indici splittati\n",
    "        \n",
    "    # Sampler\n",
    "    tr_sampler = SubsetRandomSampler(train_indices_bis)    # Train Sampler\n",
    "    d_sampler = SubsetRandomSampler(dev_indices)    # Dev Sampler\n",
    "    return tr_sampler, d_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fold 1\n",
      "Train dataset: 867073 windows;\n",
      "Test dataset (LEARNED): 96389 windows;\n",
      "Test dataset (UNLEARNED) 257150 windows.\n",
      "Loading fold 2\n",
      "Train dataset: 895932 windows;\n",
      "Test dataset (LEARNED): 99592 windows;\n",
      "Test dataset (UNLEARNED) 225088 windows.\n",
      "Loading fold 3\n",
      "Train dataset: 869368 windows;\n",
      "Test dataset (LEARNED): 96642 windows;\n",
      "Test dataset (UNLEARNED) 254602 windows.\n",
      "Loading fold 4\n",
      "Train dataset: 885991 windows;\n",
      "Test dataset (LEARNED): 98489 windows;\n",
      "Test dataset (UNLEARNED) 236132 windows.\n",
      "Loading fold 5\n",
      "Train dataset: 881308 windows;\n",
      "Test dataset (LEARNED): 97968 windows;\n",
      "Test dataset (UNLEARNED) 241336 windows.\n",
      "\n",
      "Each window is composed by 161 samples.\n",
      "The number of muscles is 8\n"
     ]
    }
   ],
   "source": [
    "#Loads and appends all folds all at once\n",
    "trainfolds = []    # Train set\n",
    "testfolds_L = []    # Test set (LEARNED)\n",
    "testfolds_U = []    # Test set (UNLEARNED)\n",
    "\n",
    "col_select = np.array([])\n",
    "\n",
    "#This is an hack to test smaller windows\n",
    "for i in range (spw*nmuscles,200):\n",
    "    col_select = np.append(col_select,i)\n",
    "    \n",
    "for i in range (0,spw*nmuscles,nmuscles):\n",
    "    for muscle in features_select:\n",
    "        col_select = np.append(col_select,muscle -1 + i)\n",
    "    cols=np.arange(0,spw*nmuscles+1)\n",
    "\n",
    "if exclude_features & (not include_only_features): #delete gonio\n",
    "    for j in range(fold_offset,fold_offset + nfold):\n",
    "        print(\"Loading fold \" + str(j))\n",
    "        traindata = pd.read_csv(os.path.join(cwd, prefix_train + '_' + str(j)+'.csv'),sep=',',header=None,dtype=np.float32,usecols=[i for i in cols if i not in col_select.astype(int)])\n",
    "        trainfolds.append(traindata)\n",
    "        testdata_L = pd.read_csv(os.path.join(cwd, prefix_test + '_L_' + str(j)+'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i not in col_select.astype(int)])\n",
    "        testfolds_L.append(testdata_L) \n",
    "        testdata_U = pd.read_csv(os.path.join(cwd, prefix_test + '_U_' + str(j) +'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i not in col_select.astype(int)])\n",
    "        testfolds_U.append(testdata_U)\n",
    "        print('Train dataset: ' + str(len(traindata)) + ' windows;')\n",
    "        print('Test dataset (LEARNED): ' + str(len(testdata_L)) + ' windows;')\n",
    "        print('Test dataset (UNLEARNED) ' + str(len(testdata_U)) + ' windows.')\n",
    "        \n",
    "elif include_only_features & (not exclude_features): #only gonio\n",
    "    for j in range(fold_offset, fold_offset + nfold):\n",
    "        print(\"Loading fold \" + str(j))\n",
    "        traindata = pd.read_csv(os.path.join(cwd, prefix_train + '_' + str(j)+'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i in col_select.astype(int)])\n",
    "        testdata_L = pd.read_csv(os.path.join(cwd, prefix_test + '_L_'+ str(j)+'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i in col_select.astype(int)])\n",
    "        testdata_U = pd.read_csv(os.path.join(cwd, prefix_test + '_U_' + str(j) +'.csv'),sep=',',header=None,dtype=np.float32, usecols=[i for i in cols if i in col_select.astype(int)])\n",
    "        trainfolds.append(traindata)\n",
    "        testfolds_L.append(testdata_L)\n",
    "        testfolds_U.append(testdata_U)\n",
    "        print('Train dataset: ' + str(len(traindata)) + ' windows;')\n",
    "        print('Test dataset (LEARNED): ' + str(len(testdata)) + ' windows;')\n",
    "        print('Test dataset (UNLEARNED) ' + str(len(testdata_U)) + ' windows.')\n",
    "        \n",
    "elif (not include_only_features) & (not exclude_features): \n",
    "    for j in range(fold_offset,fold_offset + nfold):\n",
    "        print(\"Loading fold \" + str(j))\n",
    "        traindata = pd.read_csv(os.path.join(cwd, prefix_train + '_' + str(j) + '.csv'),sep=',',header=None,dtype=np.float32)\n",
    "        testdata = pd.read_csv(os.path.join(cwd, prefix_test + '_L_' + str(j) +'.csv'),sep=',',header=None,dtype=np.float32)\n",
    "        testdata_U = pd.read_csv(os.path.join(cwd, prefix_test + '_U_' + str(j) +'.csv'),sep=',',header=None,dtype=np.float32)\n",
    "        trainfolds.append(traindata)\n",
    "        testfolds_L.append(testdata)\n",
    "        testfolds_U.append(testdata_U)    # Aggiunto testfold UNLEARNED \n",
    "        print('Train dataset: ' + str(len(traindata)) + ' windows;')\n",
    "        print('Test dataset (LEARNED): ' + str(len(testdata)) + ' windows;')\n",
    "        print('Test dataset (UNLEARNED) ' + str(len(testdata_U)) + ' windows.')\n",
    "else:\n",
    "    raise ValueError('use_gonio and del_gonio cannot be both True')\n",
    "\n",
    "nmuscles=int((len(traindata.columns)-1)/spw)\n",
    "print('\\nEach window is composed by ' + str(len(traindata.columns)) + ' samples.')\n",
    "print('The number of muscles is ' + str(nmuscles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nmuscles=int((len(traindata.columns)-1)/spw) #used for layer dimensions and stride CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import models\n",
    "from models import *\n",
    "models._spw = spw\n",
    "models._nmuscles = nmuscles\n",
    "models._batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Model23(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv1d(1, 20, kernel_size=(80,), stride=(8,))\n",
      "    (1): Conv1d(1, 20, kernel_size=(160,), stride=(8,))\n",
      "  )\n",
      "  (mp): AvgPool1d(kernel_size=(5,), stride=(5,), padding=(0,))\n",
      "  (fc1): Linear(in_features=360, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "Filter size: 80\n",
      "Filter size: 160\n",
      "Input:torch.Size([32, 1, 480])\n",
      "Features: 8\n",
      "Do convnets\n",
      "Out: torch.Size([32, 20, 51])\n",
      "Out: torch.Size([32, 20, 41])\n",
      "Do maxpool\n",
      "Out: torch.Size([32, 20, 10])\n",
      "Out: torch.Size([32, 20, 8])\n",
      "Do concat\n",
      "Out: torch.Size([32, 360])\n",
      "Do Fully connected 1\n",
      "Out: torch.Size([32, 128])\n",
      "Do Fully connected 2\n",
      "Out: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(models._nmuscles)\n",
    "\n",
    "#import models\n",
    "#from models import *\n",
    "#TEST DIMENSIONS\n",
    "#models.nmuscles = nmuscles\n",
    "def testdimensions():\n",
    "    model = Model23()\n",
    "    print(model)\n",
    "    x = torch.randn(32,1,480)\n",
    "    model.test_dim(x)\n",
    " \n",
    "testdimensions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fieldnames = ['Fold','Acc_L', 'Acc_U',\n",
    "              'R_0_U','R_1_U',\n",
    "              'R_0_L','R_1_L',\n",
    "              'Stop_epoch','Accuracy_dev'] #coloumn names report FOLD CSV\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#TRAINING LOOP\n",
    "def train_test():\n",
    "    for k in model_select:\n",
    "        \n",
    "        table = BeautifulTable()\n",
    "        avgtable = BeautifulTable()\n",
    "        fieldnames1 = [model_lst[k],'Avg','Std_dev'] #column names report GLOBAL CSV\n",
    "        folder = os.path.join(cwd,'Report_'+str(model_lst[k]))\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "        logfilepath = os.path.join(folder,'log.txt')\n",
    "        logfile = open(logfilepath,\"w\") \n",
    "\n",
    "        with open(os.path.join(folder,'Report_folds.csv'),'w') as f_fold, open(os.path.join(folder,'Report_global.csv'),'w') as f_global:\n",
    "            writer = csv.DictWriter(f_fold, fieldnames = fieldnames)\n",
    "            writer1  = csv.DictWriter(f_global, fieldnames = fieldnames1)\n",
    "            writer.writeheader()\n",
    "            writer1.writeheader()\n",
    "            t0 = 0\n",
    "            t1 = 0\n",
    "            for i in range(1,nfold+1):\n",
    "                \n",
    "                t0 = time.time()\n",
    "                setSeeds(0)\n",
    "                \n",
    "                class Traindataset(Dataset):\n",
    "                    def __init__(self):\n",
    "                        self.data=trainfolds[i-1]\n",
    "                        self.x_data=torch.from_numpy(np.asarray(self.data.iloc[:, 0:-1])) \n",
    "                        self.len=self.data.shape[0]\n",
    "                        self.y_data = torch.from_numpy(np.asarray(self.data.iloc[:, [-1]]))\n",
    "                        if (use_cuda):\n",
    "                            self.x_data = self.x_data.cuda()\n",
    "                            self.y_data = self.y_data.cuda()\n",
    "                    def __getitem__(self, index):\n",
    "                        return self.x_data[index], self.y_data[index]\n",
    "                    def __len__(self):\n",
    "                        return self.len\n",
    "                \n",
    "                # Classe per il Testset LEARNED\n",
    "                class Testdataset_L(Dataset):\n",
    "                    def __init__(self):\n",
    "                        self.data=testfolds_L[i-1]\n",
    "                        self.x_data=torch.from_numpy(np.asarray(self.data.iloc[:, 0:-1]))\n",
    "                        self.len=self.data.shape[0]\n",
    "                        self.y_data = torch.from_numpy(np.asarray(self.data.iloc[:, [-1]]))\n",
    "                        if (use_cuda):\n",
    "                            self.x_data = self.x_data.cuda()\n",
    "                            self.y_data = self.y_data.cuda()\n",
    "                    def __getitem__(self, index):\n",
    "                        return self.x_data[index], self.y_data[index]\n",
    "                    def __len__(self):\n",
    "                        return self.len\n",
    "                \n",
    "                # Classe per il Testset UNLEARNED\n",
    "                class Testdataset_U(Dataset):\n",
    "                    def __init__(self):\n",
    "                        self.data=testfolds_U[i-1]\n",
    "                        self.x_data=torch.from_numpy(np.asarray(self.data.iloc[:, 0:-1]))\n",
    "                        self.len=self.data.shape[0]\n",
    "                        self.y_data = torch.from_numpy(np.asarray(self.data.iloc[:, [-1]]))\n",
    "                        if (use_cuda):\n",
    "                            self.x_data = self.x_data.cuda()\n",
    "                            self.y_data = self.y_data.cuda()\n",
    "                    def __getitem__(self, index):\n",
    "                        return self.x_data[index], self.y_data[index]\n",
    "                    def __len__(self):\n",
    "                        return self.len\n",
    "\n",
    "                ## DEFINISCO I DATASET DA CARICARE    \n",
    "                traindataset = Traindataset()    # Train dataset\n",
    "                testdataset = Testdataset_L()    # Test dataset LEARNED\n",
    "                testdataset_U = Testdataset_U()    # Test dataset UNLEARNED\n",
    "\n",
    "                header( model_lst, k, i, traindataset, testdataset, testdataset_U)\n",
    "\n",
    "                #train_sampler,dev_sampler,test_sampler=dev_shuffle(shuffle_train,shuffle_test,val_split,traindataset,testdataset)\n",
    "                #train_sampler,dev_sampler,test_val_sampler,test_sampler=data_split(shuffle_train,shuffle_test,val_split,test_val_split,traindataset,testdataset)\n",
    "                \n",
    "                ## CREO I SAMPLER PER DIVIDERE IL TRAINDASTASET\n",
    "                tr_sampler, d_sampler = split_train(val_split, traindataset)\n",
    "                \n",
    "                ## LOADERS\n",
    "                # torch.utils.data.DataLoader deve avere come argomenti:\n",
    "                    # dataset -> quello che dobbiamo caricare\n",
    "                    # batch_size -> 'batch_size' definito negli hyperparameter della rete\n",
    "                    # drop_last = True -> Se la lunghezza del dataset non è divisibile per 'batch_size', \n",
    "                    # l'ultimo batch viene eliminato\n",
    "                # 'dev_loader e 'train_loader' hanno bisogno anche di\n",
    "                    # sampler = dev_sampler (una certa parte del trainset \n",
    "                    # deve essere usata come 'dev_set')\n",
    "                \n",
    "                # Training Set\n",
    "                train_loader = torch.utils.data.DataLoader(traindataset, batch_size = batch_size, \n",
    "                                                          sampler = tr_sampler, drop_last = True)\n",
    "                print('Train Set dimension: ' + str(len(train_loader)))\n",
    "                # Development Set\n",
    "                dev_loader = torch.utils.data.DataLoader(traindataset, batch_size=batch_size, \n",
    "                                                           sampler = d_sampler, drop_last=True)\n",
    "                print('Dev Set dimension: ' + str(len(dev_loader)))\n",
    "                # Testset LEARNED\n",
    "                test_val_loader = torch.utils.data.DataLoader(testdataset, batch_size=batch_size,\n",
    "                                                                drop_last=True)\n",
    "                print('Test Set (L) dimension: ' + str(len(test_val_loader)))\n",
    "                # Testset UNLEARNED\n",
    "                test_loader = torch.utils.data.DataLoader(testdataset_U, batch_size = batch_size, \n",
    "                                                          drop_last = True)\n",
    "                print('Test Set (U) dimension: ' + str(len(test_loader)))\n",
    "                \n",
    "                modelClass = \"Model\" + str(k)\n",
    "                model = eval(modelClass)()\n",
    "                \n",
    "                if (use_cuda):\n",
    "                    model = model.cuda()\n",
    "\n",
    "                if doTrain:\n",
    "                    \n",
    "                    # criterion = nn.BCELoss(size_average=True)\n",
    "                    criterion = nn.BCELoss(reduction = 'mean')    # Cambiato perché dava un warning (size_average era un vecchio metodo in Pytorch)\n",
    "                    optimizer = torch.optim.SGD(model.parameters(), lr)    \n",
    "                    msg = 'Accuracy on test set before training: '+str(accuracy(test_loader, model))+'\\n'\n",
    "                    print(msg)\n",
    "                    logfile.write(msg + \"\\n\")\n",
    "                    #EARLY STOP\n",
    "                    epoch = 0\n",
    "                    patience = 0\n",
    "                    best_acc_dev=0\n",
    "                    while (epoch<maxepoch and patience < maxpatience):\n",
    "                        running_loss = 0.0\n",
    "                        for l, data in enumerate(train_loader, 0):\n",
    "                            inputs, labels = data\n",
    "                            if use_cuda:\n",
    "                                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                            inputs, labels = Variable(inputs), Variable(labels)\n",
    "                            y_pred = model(inputs)\n",
    "                            if use_cuda:\n",
    "                                y_pred = y_pred.cuda()\n",
    "                            loss = criterion(y_pred, labels)\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            running_loss += loss.item()\n",
    "                            #print accuracy ever l mini-batches\n",
    "                            if l % 2000 == 1999:\n",
    "                                msg = '[%d, %5d] loss: %.3f' %(epoch + 1, l + 1, running_loss / 999)\n",
    "                                print(msg)\n",
    "                                logfile.write(msg + \"\\n\")\n",
    "                                running_loss = 0.0\n",
    "                                #msg = 'Accuracy on dev set:' + str(accuracy(dev_loader))\n",
    "                                #print(msg)\n",
    "                                #logfile.write(msg + \"\\n\")        \n",
    "                        accdev = (accuracy(dev_loader, model))\n",
    "                        msg = 'Accuracy on dev set:' + str(accdev)\n",
    "                        print(msg)\n",
    "                        logfile.write(msg + \"\\n\")        \n",
    "                        is_best = bool(accdev > best_acc_dev)\n",
    "                        best_acc_dev = (max(accdev, best_acc_dev))\n",
    "                        save_checkpoint({\n",
    "                            'epoch': epoch + 1,\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'best_acc_dev': best_acc_dev\n",
    "                        }, is_best,os.path.join(folder,'F'+str(i)+'best.pth.tar'), logfile)\n",
    "                        if is_best:\n",
    "                            patience=0\n",
    "                        else:\n",
    "                            patience = patience+1\n",
    "                        epoch = epoch+1\n",
    "                        logfile.flush()\n",
    "                        \n",
    "                if doEval:\n",
    "                    if use_cuda:                        \n",
    "                        state = torch.load(os.path.join(folder,'F'+str(i)+'best.pth.tar'))\n",
    "                    else:\n",
    "                        state = torch.load(os.path.join(folder,'F'+str(i)+'best.pth.tar'), map_location=lambda storage, loc: storage)\n",
    "                    stop_epoch = state['epoch']\n",
    "                    model.load_state_dict(state['state_dict'])\n",
    "                    if not use_cuda:\n",
    "                        model.cpu()\n",
    "                    accuracy_dev = state['best_acc_dev']\n",
    "                    model.eval()\n",
    "                    acctest = (accuracy(test_loader, model))\n",
    "                    acctest_val = (accuracy(test_val_loader, model))\n",
    "                    accs[i-1] = acctest\n",
    "                    accs_test_val[i-1] = acctest_val\n",
    "                    \n",
    "                    precision_0_U,recall_0_U,f1_score_0_U = pre_rec(test_loader, model, 0.0)\n",
    "                    precisions_0_U[i-1] = precision_0_U\n",
    "                    recalls_0_U[i-1] = recall_0_U\n",
    "                    f1_scores_0_U[i-1] = f1_score_0_U\n",
    "                    \n",
    "                    precision_1_U,recall_1_U,f1_score_1_U = pre_rec(test_loader, model, 1.0)\n",
    "                    precisions_1_U[i-1] = precision_1_U\n",
    "                    recalls_1_U[i-1] = recall_1_U\n",
    "                    f1_scores_1_U[i-1] = f1_score_1_U\n",
    "                    \n",
    "                    precision_0_L,recall_0_L,f1_score_0_L = pre_rec(test_val_loader, model, 0.0)\n",
    "                    precisions_0_L[i-1] = precision_0_L\n",
    "                    recalls_0_L[i-1] = recall_0_L\n",
    "                    f1_scores_0_L[i-1] = f1_score_0_L\n",
    "                    \n",
    "                    precision_1_L,recall_1_L,f1_score_1_L = pre_rec(test_val_loader, model, 1.0)\n",
    "                    precisions_1_L[i-1] = precision_1_L\n",
    "                    recalls_1_L[i-1] = recall_1_L\n",
    "                    f1_scores_1_L[i-1] = f1_score_1_L\n",
    "                    \n",
    "                    accs_dev[i-1] = accuracy_dev\n",
    "                    \n",
    "                    writer.writerow({'Fold': i,'Acc_L': acctest_val, 'Acc_U': acctest,\n",
    "                                     #'P_0_U': precision_0_U,'R_0_U': recall_0_U,'F1_0_U': f1_score_0_U,\n",
    "                                     'R_0_U': recall_0_U,\n",
    "                                     #'P_1_U': precision_1_U,'R_1_U': recall_1_U,'F1_1_U': f1_score_1_U,\n",
    "                                     'R_1_U': recall_1_U,\n",
    "                                     #'P_0_L': precision_0_L,'R_0_L': recall_0_L,'F1_0_L': f1_score_0_L,\n",
    "                                     'R_0_L': recall_0_L,\n",
    "                                     #'P_1_L': precision_1_L,'R_1_L': recall_1_L,'F1_1_L': f1_score_1_L,\n",
    "                                     'R_1_L': recall_1_L,\n",
    "                                     'Stop_epoch': stop_epoch,'Accuracy_dev': accuracy_dev})\n",
    "                    table.column_headers = fieldnames\n",
    "                    table.append_row([i,acctest_val,acctest,\n",
    "                                      #precision_0_U,recall_0_U,f1_score_0_U,\n",
    "                                      recall_0_U,\n",
    "                                      #precision_1_U,recall_1_U,f1_score_1_U,\n",
    "                                      recall_1_U,\n",
    "                                      #precision_0_L,recall_0_L,f1_score_0_L,\n",
    "                                      recall_0_L,\n",
    "                                      #precision_1_L,recall_1_L,f1_score_1_L,\n",
    "                                      recall_1_L,\n",
    "                                      stop_epoch,accuracy_dev])\n",
    "                    print(table)\n",
    "                    print('----------------------------------------------------------------------')\n",
    "                    logfile.write(str(table) + \"\\n----------------------------------------------------------------------\\n\")\n",
    "                    t1 = time.time()\n",
    "                    times[i-1] = int(t1-t0)\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=np.sum(times)))\n",
    "            writer.writerow({})\n",
    "            writer.writerow({'Fold': 'Elapsed time: '+duration})\n",
    "            avg_acc_test_val = round(np.average(accs_test_val),3)\n",
    "            std_acc_test_val = round(np.std(accs_test_val),3)\n",
    "            \n",
    "            avg_acc_test_val,avg_a,avg_p_0_U,avg_r_0_U,avg_f_0_U,avg_p_1_U,avg_r_1_U,avg_f_1_U,avg_p_0_L,avg_r_0_L,avg_f_0_L,avg_p_1_L,avg_r_1_L,avg_f_1_L,avg_a_d=averages([accs_test_val,accs,precisions_0_U,recalls_0_U,f1_scores_0_U,precisions_1_U,recalls_1_U,f1_scores_1_U,precisions_0_L,recalls_0_L,f1_scores_0_L,precisions_1_L,recalls_1_L,f1_scores_1_L,accs_dev])\n",
    "            std_acc_test_val,std_a,std_p_0_U,std_r_0_U,std_f_0_U,std_p_1_U,std_r_1_U,std_f_1_U,std_p_0_L,std_r_0_L,std_f_0_L,std_p_1_L,std_r_1_L,std_f_1_L,std_a_d=stds([accs_test_val,accs,precisions_0_U,recalls_0_U,f1_scores_0_U,precisions_1_U,recalls_1_U,f1_scores_1_U,precisions_0_L,recalls_0_L,f1_scores_0_L,precisions_1_L,recalls_1_L,f1_scores_1_L,accs_dev])\n",
    "            \n",
    "            writer1.writerow({model_lst[k]: 'Acc_U','Avg': avg_a,'Std_dev': std_acc_test_val})\n",
    "            writer1.writerow({model_lst[k]: 'Acc_L','Avg': avg_acc_test_val,'Std_dev': std_a})\n",
    "            writer1.writerow({model_lst[k]: 'P_0_U','Avg': avg_p_0_U ,'Std_dev': std_p_0_U})\n",
    "            writer1.writerow({model_lst[k]: 'R_0_U','Avg': avg_r_0_U,'Std_dev': std_r_0_U})\n",
    "            writer1.writerow({model_lst[k]: 'F1_0_U','Avg': avg_f_0_U,'Std_dev': std_f_0_U})\n",
    "            writer1.writerow({model_lst[k]: 'P_1_U','Avg': avg_p_1_U,'Std_dev': std_p_1_U})\n",
    "            writer1.writerow({model_lst[k]: 'R_1_U','Avg': avg_r_1_U,'Std_dev': std_r_1_U})\n",
    "            writer1.writerow({model_lst[k]: 'F1_1_U','Avg': avg_f_1_U,'Std_dev': std_f_1_U})            \n",
    "            writer1.writerow({model_lst[k]: 'P_0_L','Avg': avg_p_0_L,'Std_dev': std_p_0_L})\n",
    "            writer1.writerow({model_lst[k]: 'R_0_L','Avg': avg_r_0_L,'Std_dev': std_r_0_L})\n",
    "            writer1.writerow({model_lst[k]: 'F1_0_L','Avg': avg_f_0_L,'Std_dev': std_f_0_L})\n",
    "            writer1.writerow({model_lst[k]: 'P_1_L','Avg': avg_p_1_L,'Std_dev': std_p_1_L})\n",
    "            writer1.writerow({model_lst[k]: 'R_1_L','Avg': avg_r_1_L,'Std_dev': std_r_1_L})\n",
    "            writer1.writerow({model_lst[k]: 'F1_1_L','Avg': avg_f_1_L,'Std_dev': std_f_1_L})                        \n",
    "            writer1.writerow({model_lst[k]: 'Acc_dev','Avg': avg_a_d,'Std_dev': std_a_d})\n",
    "            writer1.writerow({})\n",
    "            writer1.writerow({model_lst[k]: 'Elapsed time: '+duration})\n",
    "            avgtable.column_headers = fieldnames1\n",
    "            avgtable.append_row(['Acc_U',avg_a,std_a])\n",
    "            avgtable.append_row(['Acc_L',avg_acc_test_val,std_acc_test_val])\n",
    "            avgtable.append_row(['P_0_U',avg_p_0_U,std_p_0_U])\n",
    "            avgtable.append_row(['R_0_U',avg_r_0_U,std_r_0_U])\n",
    "            avgtable.append_row(['F1_0_U',avg_f_0_U,std_f_0_U])\n",
    "            avgtable.append_row(['P_1_U',avg_p_1_U,std_p_1_U])\n",
    "            avgtable.append_row(['R_1_U',avg_r_1_U,std_r_1_U])\n",
    "            avgtable.append_row(['F1_1_U',avg_f_1_U,std_f_1_U])                        \n",
    "            avgtable.append_row(['P_0_L',avg_p_0_L,std_p_0_L])\n",
    "            avgtable.append_row(['R_0_L',avg_r_0_L,std_r_0_L])\n",
    "            avgtable.append_row(['F1_0_L',avg_f_0_L,std_f_0_L])\n",
    "            avgtable.append_row(['P_1_L',avg_p_1_L,std_p_1_L])\n",
    "            avgtable.append_row(['R_1_L',avg_r_1_L,std_r_1_L])\n",
    "            avgtable.append_row(['F1_1_L',avg_f_1_L,std_f_1_L])            \n",
    "            avgtable.append_row(['Accuracy_dev',avg_a_d,std_a_d])\n",
    "            print(avgtable)\n",
    "            logfile.write(str(avgtable) + \"\\n\")\n",
    "            msg = 'Elapsed time: '+ duration + '\\n\\n'\n",
    "            print(msg)\n",
    "            logfile.write(msg )\n",
    "\n",
    "        logfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am NOT using CUDA: SUCCESS!\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF4\n",
      "Fold: 1\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 867073x161\n",
      "Testset (L) fold228 shape: 96389x161\n",
      "Testset (U) fold228 shape: 257150x161\n",
      "\n",
      "Train Set dimension: 21676\n",
      "Dev Set dimension: 5419\n",
      "Test Set (L) dimension: 3012\n",
      "Test Set (U) dimension: 8035\n",
      "Accuracy on test set before training: 46.077\n",
      "\n",
      "[1,  2000] loss: 0.786\n",
      "[1,  4000] loss: 0.539\n",
      "[1,  6000] loss: 0.539\n",
      "[1,  8000] loss: 0.519\n",
      "[1, 10000] loss: 0.505\n",
      "[1, 12000] loss: 0.492\n",
      "[1, 14000] loss: 0.476\n",
      "[1, 16000] loss: 0.472\n",
      "[1, 18000] loss: 0.461\n",
      "[1, 20000] loss: 0.449\n",
      "Accuracy on dev set:87.87\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.436\n",
      "[2,  4000] loss: 0.425\n",
      "[2,  6000] loss: 0.429\n",
      "[2,  8000] loss: 0.417\n",
      "[2, 10000] loss: 0.421\n",
      "[2, 12000] loss: 0.427\n",
      "[2, 14000] loss: 0.416\n",
      "[2, 16000] loss: 0.412\n",
      "[2, 18000] loss: 0.398\n",
      "[2, 20000] loss: 0.403\n",
      "Accuracy on dev set:87.828\n",
      "=> Validation accuracy did not improve. Epoch: 2\n",
      "[3,  2000] loss: 0.400\n",
      "[3,  4000] loss: 0.397\n",
      "[3,  6000] loss: 0.389\n",
      "[3,  8000] loss: 0.387\n",
      "[3, 10000] loss: 0.383\n",
      "[3, 12000] loss: 0.396\n",
      "[3, 14000] loss: 0.386\n",
      "[3, 16000] loss: 0.388\n",
      "[3, 18000] loss: 0.392\n",
      "[3, 20000] loss: 0.385\n",
      "Accuracy on dev set:88.116\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.378\n",
      "[4,  4000] loss: 0.375\n",
      "[4,  6000] loss: 0.385\n",
      "[4,  8000] loss: 0.382\n",
      "[4, 10000] loss: 0.377\n",
      "[4, 12000] loss: 0.375\n",
      "[4, 14000] loss: 0.378\n",
      "[4, 16000] loss: 0.372\n",
      "[4, 18000] loss: 0.376\n",
      "[4, 20000] loss: 0.373\n",
      "Accuracy on dev set:87.282\n",
      "=> Validation accuracy did not improve. Epoch: 4\n",
      "[5,  2000] loss: 0.379\n",
      "[5,  4000] loss: 0.372\n",
      "[5,  6000] loss: 0.367\n",
      "[5,  8000] loss: 0.370\n",
      "[5, 10000] loss: 0.366\n",
      "[5, 12000] loss: 0.368\n",
      "[5, 14000] loss: 0.369\n",
      "[5, 16000] loss: 0.361\n",
      "[5, 18000] loss: 0.360\n",
      "[5, 20000] loss: 0.364\n",
      "Accuracy on dev set:87.854\n",
      "=> Validation accuracy did not improve. Epoch: 5\n",
      "[6,  2000] loss: 0.364\n",
      "[6,  4000] loss: 0.361\n",
      "[6,  6000] loss: 0.357\n",
      "[6,  8000] loss: 0.368\n",
      "[6, 10000] loss: 0.361\n",
      "[6, 12000] loss: 0.361\n",
      "[6, 14000] loss: 0.361\n",
      "[6, 16000] loss: 0.351\n",
      "[6, 18000] loss: 0.355\n",
      "[6, 20000] loss: 0.360\n",
      "Accuracy on dev set:88.426\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.357\n",
      "[7,  4000] loss: 0.352\n",
      "[7,  6000] loss: 0.356\n",
      "[7,  8000] loss: 0.361\n",
      "[7, 10000] loss: 0.353\n",
      "[7, 12000] loss: 0.358\n",
      "[7, 14000] loss: 0.349\n",
      "[7, 16000] loss: 0.348\n",
      "[7, 18000] loss: 0.355\n",
      "[7, 20000] loss: 0.353\n",
      "Accuracy on dev set:88.307\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.354\n",
      "[8,  4000] loss: 0.353\n",
      "[8,  6000] loss: 0.352\n",
      "[8,  8000] loss: 0.347\n",
      "[8, 10000] loss: 0.350\n",
      "[8, 12000] loss: 0.351\n",
      "[8, 14000] loss: 0.347\n",
      "[8, 16000] loss: 0.347\n",
      "[8, 18000] loss: 0.343\n",
      "[8, 20000] loss: 0.349\n",
      "Accuracy on dev set:88.293\n",
      "=> Validation accuracy did not improve. Epoch: 8\n",
      "[9,  2000] loss: 0.339\n",
      "[9,  4000] loss: 0.347\n",
      "[9,  6000] loss: 0.343\n",
      "[9,  8000] loss: 0.345\n",
      "[9, 10000] loss: 0.347\n",
      "[9, 12000] loss: 0.349\n",
      "[9, 14000] loss: 0.350\n",
      "[9, 16000] loss: 0.347\n",
      "[9, 18000] loss: 0.351\n",
      "[9, 20000] loss: 0.334\n",
      "Accuracy on dev set:87.972\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.335\n",
      "[10,  4000] loss: 0.334\n",
      "[10,  6000] loss: 0.348\n",
      "[10,  8000] loss: 0.342\n",
      "[10, 10000] loss: 0.345\n",
      "[10, 12000] loss: 0.343\n",
      "[10, 14000] loss: 0.337\n",
      "[10, 16000] loss: 0.346\n",
      "[10, 18000] loss: 0.335\n",
      "[10, 20000] loss: 0.337\n",
      "Accuracy on dev set:88.221\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.341\n",
      "[11,  4000] loss: 0.335\n",
      "[11,  6000] loss: 0.332\n",
      "[11,  8000] loss: 0.330\n",
      "[11, 10000] loss: 0.333\n",
      "[11, 12000] loss: 0.336\n",
      "[11, 14000] loss: 0.339\n",
      "[11, 16000] loss: 0.342\n",
      "[11, 18000] loss: 0.335\n",
      "[11, 20000] loss: 0.334\n",
      "Accuracy on dev set:87.678\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.330\n",
      "[12,  4000] loss: 0.338\n",
      "[12,  6000] loss: 0.334\n",
      "[12,  8000] loss: 0.333\n",
      "[12, 10000] loss: 0.336\n",
      "[12, 12000] loss: 0.333\n",
      "[12, 14000] loss: 0.327\n",
      "[12, 16000] loss: 0.337\n",
      "[12, 18000] loss: 0.337\n",
      "[12, 20000] loss: 0.333\n",
      "Accuracy on dev set:87.877\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.330\n",
      "[13,  4000] loss: 0.330\n",
      "[13,  6000] loss: 0.328\n",
      "[13,  8000] loss: 0.333\n",
      "[13, 10000] loss: 0.328\n",
      "[13, 12000] loss: 0.334\n",
      "[13, 14000] loss: 0.334\n",
      "[13, 16000] loss: 0.325\n",
      "[13, 18000] loss: 0.329\n",
      "[13, 20000] loss: 0.326\n",
      "Accuracy on dev set:88.499\n",
      "=> Saving a new best. Epoch: 13\n",
      "[14,  2000] loss: 0.332\n",
      "[14,  4000] loss: 0.318\n",
      "[14,  6000] loss: 0.328\n",
      "[14,  8000] loss: 0.335\n",
      "[14, 10000] loss: 0.335\n",
      "[14, 12000] loss: 0.334\n",
      "[14, 14000] loss: 0.320\n",
      "[14, 16000] loss: 0.326\n",
      "[14, 18000] loss: 0.320\n",
      "[14, 20000] loss: 0.329\n",
      "Accuracy on dev set:88.42\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.325\n",
      "[15,  4000] loss: 0.336\n",
      "[15,  6000] loss: 0.324\n",
      "[15,  8000] loss: 0.321\n",
      "[15, 10000] loss: 0.324\n",
      "[15, 12000] loss: 0.322\n",
      "[15, 14000] loss: 0.322\n",
      "[15, 16000] loss: 0.322\n",
      "[15, 18000] loss: 0.325\n",
      "[15, 20000] loss: 0.322\n",
      "Accuracy on dev set:88.471\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.321\n",
      "[16,  4000] loss: 0.323\n",
      "[16,  6000] loss: 0.321\n",
      "[16,  8000] loss: 0.324\n",
      "[16, 10000] loss: 0.319\n",
      "[16, 12000] loss: 0.321\n",
      "[16, 14000] loss: 0.319\n",
      "[16, 16000] loss: 0.322\n",
      "[16, 18000] loss: 0.320\n",
      "[16, 20000] loss: 0.329\n",
      "Accuracy on dev set:88.417\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.318\n",
      "[17,  4000] loss: 0.316\n",
      "[17,  6000] loss: 0.321\n",
      "[17,  8000] loss: 0.324\n",
      "[17, 10000] loss: 0.318\n",
      "[17, 12000] loss: 0.320\n",
      "[17, 14000] loss: 0.316\n",
      "[17, 16000] loss: 0.322\n",
      "[17, 18000] loss: 0.319\n",
      "[17, 20000] loss: 0.318\n",
      "Accuracy on dev set:88.084\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.315\n",
      "[18,  4000] loss: 0.315\n",
      "[18,  6000] loss: 0.315\n",
      "[18,  8000] loss: 0.317\n",
      "[18, 10000] loss: 0.323\n",
      "[18, 12000] loss: 0.319\n",
      "[18, 14000] loss: 0.317\n",
      "[18, 16000] loss: 0.315\n",
      "[18, 18000] loss: 0.319\n",
      "[18, 20000] loss: 0.318\n",
      "Accuracy on dev set:88.17\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.317\n",
      "[19,  4000] loss: 0.312\n",
      "[19,  6000] loss: 0.321\n",
      "[19,  8000] loss: 0.318\n",
      "[19, 10000] loss: 0.314\n",
      "[19, 12000] loss: 0.311\n",
      "[19, 14000] loss: 0.320\n",
      "[19, 16000] loss: 0.310\n",
      "[19, 18000] loss: 0.317\n",
      "[19, 20000] loss: 0.311\n",
      "Accuracy on dev set:88.34\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.322\n",
      "[20,  4000] loss: 0.315\n",
      "[20,  6000] loss: 0.311\n",
      "[20,  8000] loss: 0.306\n",
      "[20, 10000] loss: 0.309\n",
      "[20, 12000] loss: 0.311\n",
      "[20, 14000] loss: 0.314\n",
      "[20, 16000] loss: 0.310\n",
      "[20, 18000] loss: 0.317\n",
      "[20, 20000] loss: 0.310\n",
      "Accuracy on dev set:88.484\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.312\n",
      "[21,  4000] loss: 0.306\n",
      "[21,  6000] loss: 0.315\n",
      "[21,  8000] loss: 0.310\n",
      "[21, 10000] loss: 0.305\n",
      "[21, 12000] loss: 0.315\n",
      "[21, 14000] loss: 0.311\n",
      "[21, 16000] loss: 0.310\n",
      "[21, 18000] loss: 0.307\n",
      "[21, 20000] loss: 0.312\n",
      "Accuracy on dev set:88.364\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.305\n",
      "[22,  4000] loss: 0.305\n",
      "[22,  6000] loss: 0.304\n",
      "[22,  8000] loss: 0.316\n",
      "[22, 10000] loss: 0.309\n",
      "[22, 12000] loss: 0.302\n",
      "[22, 14000] loss: 0.305\n",
      "[22, 16000] loss: 0.308\n",
      "[22, 18000] loss: 0.313\n",
      "[22, 20000] loss: 0.308\n",
      "Accuracy on dev set:88.695\n",
      "=> Saving a new best. Epoch: 22\n",
      "[23,  2000] loss: 0.302\n",
      "[23,  4000] loss: 0.303\n",
      "[23,  6000] loss: 0.308\n",
      "[23,  8000] loss: 0.306\n",
      "[23, 10000] loss: 0.314\n",
      "[23, 12000] loss: 0.303\n",
      "[23, 14000] loss: 0.308\n",
      "[23, 16000] loss: 0.311\n",
      "[23, 18000] loss: 0.305\n",
      "[23, 20000] loss: 0.302\n",
      "Accuracy on dev set:87.512\n",
      "=> Validation accuracy did not improve. Epoch: 23\n",
      "[24,  2000] loss: 0.307\n",
      "[24,  4000] loss: 0.308\n",
      "[24,  6000] loss: 0.303\n",
      "[24,  8000] loss: 0.295\n",
      "[24, 10000] loss: 0.301\n",
      "[24, 12000] loss: 0.305\n",
      "[24, 14000] loss: 0.300\n",
      "[24, 16000] loss: 0.313\n",
      "[24, 18000] loss: 0.299\n",
      "[24, 20000] loss: 0.309\n",
      "Accuracy on dev set:88.326\n",
      "=> Validation accuracy did not improve. Epoch: 24\n",
      "[25,  2000] loss: 0.302\n",
      "[25,  4000] loss: 0.307\n",
      "[25,  6000] loss: 0.303\n",
      "[25,  8000] loss: 0.299\n",
      "[25, 10000] loss: 0.289\n",
      "[25, 12000] loss: 0.302\n",
      "[25, 14000] loss: 0.309\n",
      "[25, 16000] loss: 0.301\n",
      "[25, 18000] loss: 0.302\n",
      "[25, 20000] loss: 0.305\n",
      "Accuracy on dev set:87.612\n",
      "=> Validation accuracy did not improve. Epoch: 25\n",
      "[26,  2000] loss: 0.303\n",
      "[26,  4000] loss: 0.299\n",
      "[26,  6000] loss: 0.300\n",
      "[26,  8000] loss: 0.298\n",
      "[26, 10000] loss: 0.305\n",
      "[26, 12000] loss: 0.303\n",
      "[26, 14000] loss: 0.300\n",
      "[26, 16000] loss: 0.305\n",
      "[26, 18000] loss: 0.297\n",
      "[26, 20000] loss: 0.297\n",
      "Accuracy on dev set:88.328\n",
      "=> Validation accuracy did not improve. Epoch: 26\n",
      "[27,  2000] loss: 0.302\n",
      "[27,  4000] loss: 0.296\n",
      "[27,  6000] loss: 0.293\n",
      "[27,  8000] loss: 0.298\n",
      "[27, 10000] loss: 0.301\n",
      "[27, 12000] loss: 0.290\n",
      "[27, 14000] loss: 0.301\n",
      "[27, 16000] loss: 0.302\n",
      "[27, 18000] loss: 0.298\n",
      "[27, 20000] loss: 0.302\n",
      "Accuracy on dev set:88.111\n",
      "=> Validation accuracy did not improve. Epoch: 27\n",
      "[28,  2000] loss: 0.298\n",
      "[28,  4000] loss: 0.303\n",
      "[28,  6000] loss: 0.297\n",
      "[28,  8000] loss: 0.295\n",
      "[28, 10000] loss: 0.295\n",
      "[28, 12000] loss: 0.293\n",
      "[28, 14000] loss: 0.303\n",
      "[28, 16000] loss: 0.291\n",
      "[28, 18000] loss: 0.300\n",
      "[28, 20000] loss: 0.294\n",
      "Accuracy on dev set:88.419\n",
      "=> Validation accuracy did not improve. Epoch: 28\n",
      "[29,  2000] loss: 0.292\n",
      "[29,  4000] loss: 0.296\n",
      "[29,  6000] loss: 0.299\n",
      "[29,  8000] loss: 0.291\n",
      "[29, 10000] loss: 0.297\n",
      "[29, 12000] loss: 0.297\n",
      "[29, 14000] loss: 0.299\n",
      "[29, 16000] loss: 0.292\n",
      "[29, 18000] loss: 0.294\n",
      "[29, 20000] loss: 0.299\n",
      "Accuracy on dev set:88.573\n",
      "=> Validation accuracy did not improve. Epoch: 29\n",
      "[30,  2000] loss: 0.293\n",
      "[30,  4000] loss: 0.297\n",
      "[30,  6000] loss: 0.291\n",
      "[30,  8000] loss: 0.299\n",
      "[30, 10000] loss: 0.300\n",
      "[30, 12000] loss: 0.287\n",
      "[30, 14000] loss: 0.295\n",
      "[30, 16000] loss: 0.295\n",
      "[30, 18000] loss: 0.293\n",
      "[30, 20000] loss: 0.293\n",
      "Accuracy on dev set:88.208\n",
      "=> Validation accuracy did not improve. Epoch: 30\n",
      "[31,  2000] loss: 0.296\n",
      "[31,  4000] loss: 0.292\n",
      "[31,  6000] loss: 0.289\n",
      "[31,  8000] loss: 0.296\n",
      "[31, 10000] loss: 0.288\n",
      "[31, 12000] loss: 0.292\n",
      "[31, 14000] loss: 0.289\n",
      "[31, 16000] loss: 0.292\n",
      "[31, 18000] loss: 0.293\n",
      "[31, 20000] loss: 0.292\n",
      "Accuracy on dev set:88.156\n",
      "=> Validation accuracy did not improve. Epoch: 31\n",
      "[32,  2000] loss: 0.299\n",
      "[32,  4000] loss: 0.294\n",
      "[32,  6000] loss: 0.286\n",
      "[32,  8000] loss: 0.285\n",
      "[32, 10000] loss: 0.291\n",
      "[32, 12000] loss: 0.289\n",
      "[32, 14000] loss: 0.296\n",
      "[32, 16000] loss: 0.284\n",
      "[32, 18000] loss: 0.286\n",
      "[32, 20000] loss: 0.292\n",
      "Accuracy on dev set:87.806\n",
      "=> Validation accuracy did not improve. Epoch: 32\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 90.12 | 89.45 | 87.92 | 90.76 | 91.04 | 89.46 |    22    |   88.695   |\n",
      "|      |       |   1   |       |   3   |       |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF4\n",
      "Fold: 2\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 895932x161\n",
      "Testset (L) fold228 shape: 99592x161\n",
      "Testset (U) fold228 shape: 225088x161\n",
      "\n",
      "Train Set dimension: 22398\n",
      "Dev Set dimension: 5599\n",
      "Test Set (L) dimension: 3112\n",
      "Test Set (U) dimension: 7034\n",
      "Accuracy on test set before training: 43.355\n",
      "\n",
      "[1,  2000] loss: 0.795\n",
      "[1,  4000] loss: 0.555\n",
      "[1,  6000] loss: 0.540\n",
      "[1,  8000] loss: 0.525\n",
      "[1, 10000] loss: 0.511\n",
      "[1, 12000] loss: 0.493\n",
      "[1, 14000] loss: 0.487\n",
      "[1, 16000] loss: 0.469\n",
      "[1, 18000] loss: 0.463\n",
      "[1, 20000] loss: 0.459\n",
      "[1, 22000] loss: 0.447\n",
      "Accuracy on dev set:89.041\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.434\n",
      "[2,  4000] loss: 0.425\n",
      "[2,  6000] loss: 0.429\n",
      "[2,  8000] loss: 0.417\n",
      "[2, 10000] loss: 0.411\n",
      "[2, 12000] loss: 0.419\n",
      "[2, 14000] loss: 0.402\n",
      "[2, 16000] loss: 0.406\n",
      "[2, 18000] loss: 0.401\n",
      "[2, 20000] loss: 0.406\n",
      "[2, 22000] loss: 0.398\n",
      "Accuracy on dev set:89.942\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.391\n",
      "[3,  4000] loss: 0.393\n",
      "[3,  6000] loss: 0.392\n",
      "[3,  8000] loss: 0.381\n",
      "[3, 10000] loss: 0.393\n",
      "[3, 12000] loss: 0.384\n",
      "[3, 14000] loss: 0.386\n",
      "[3, 16000] loss: 0.380\n",
      "[3, 18000] loss: 0.390\n",
      "[3, 20000] loss: 0.384\n",
      "[3, 22000] loss: 0.385\n",
      "Accuracy on dev set:90.118\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.373\n",
      "[4,  4000] loss: 0.383\n",
      "[4,  6000] loss: 0.383\n",
      "[4,  8000] loss: 0.383\n",
      "[4, 10000] loss: 0.377\n",
      "[4, 12000] loss: 0.375\n",
      "[4, 14000] loss: 0.365\n",
      "[4, 16000] loss: 0.373\n",
      "[4, 18000] loss: 0.377\n",
      "[4, 20000] loss: 0.374\n",
      "[4, 22000] loss: 0.368\n",
      "Accuracy on dev set:90.316\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.369\n",
      "[5,  4000] loss: 0.364\n",
      "[5,  6000] loss: 0.368\n",
      "[5,  8000] loss: 0.369\n",
      "[5, 10000] loss: 0.365\n",
      "[5, 12000] loss: 0.361\n",
      "[5, 14000] loss: 0.373\n",
      "[5, 16000] loss: 0.357\n",
      "[5, 18000] loss: 0.371\n",
      "[5, 20000] loss: 0.371\n",
      "[5, 22000] loss: 0.370\n",
      "Accuracy on dev set:90.47\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.363\n",
      "[6,  4000] loss: 0.359\n",
      "[6,  6000] loss: 0.352\n",
      "[6,  8000] loss: 0.372\n",
      "[6, 10000] loss: 0.352\n",
      "[6, 12000] loss: 0.361\n",
      "[6, 14000] loss: 0.362\n",
      "[6, 16000] loss: 0.361\n",
      "[6, 18000] loss: 0.357\n",
      "[6, 20000] loss: 0.359\n",
      "[6, 22000] loss: 0.365\n",
      "Accuracy on dev set:90.44\n",
      "=> Validation accuracy did not improve. Epoch: 6\n",
      "[7,  2000] loss: 0.360\n",
      "[7,  4000] loss: 0.355\n",
      "[7,  6000] loss: 0.358\n",
      "[7,  8000] loss: 0.357\n",
      "[7, 10000] loss: 0.347\n",
      "[7, 12000] loss: 0.347\n",
      "[7, 14000] loss: 0.360\n",
      "[7, 16000] loss: 0.352\n",
      "[7, 18000] loss: 0.356\n",
      "[7, 20000] loss: 0.356\n",
      "[7, 22000] loss: 0.357\n",
      "Accuracy on dev set:90.609\n",
      "=> Saving a new best. Epoch: 7\n",
      "[8,  2000] loss: 0.353\n",
      "[8,  4000] loss: 0.344\n",
      "[8,  6000] loss: 0.355\n",
      "[8,  8000] loss: 0.350\n",
      "[8, 10000] loss: 0.346\n",
      "[8, 12000] loss: 0.360\n",
      "[8, 14000] loss: 0.348\n",
      "[8, 16000] loss: 0.346\n",
      "[8, 18000] loss: 0.350\n",
      "[8, 20000] loss: 0.348\n",
      "[8, 22000] loss: 0.347\n",
      "Accuracy on dev set:90.241\n",
      "=> Validation accuracy did not improve. Epoch: 8\n",
      "[9,  2000] loss: 0.351\n",
      "[9,  4000] loss: 0.354\n",
      "[9,  6000] loss: 0.346\n",
      "[9,  8000] loss: 0.347\n",
      "[9, 10000] loss: 0.346\n",
      "[9, 12000] loss: 0.343\n",
      "[9, 14000] loss: 0.340\n",
      "[9, 16000] loss: 0.342\n",
      "[9, 18000] loss: 0.338\n",
      "[9, 20000] loss: 0.346\n",
      "[9, 22000] loss: 0.344\n",
      "Accuracy on dev set:90.017\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.342\n",
      "[10,  4000] loss: 0.346\n",
      "[10,  6000] loss: 0.344\n",
      "[10,  8000] loss: 0.343\n",
      "[10, 10000] loss: 0.337\n",
      "[10, 12000] loss: 0.338\n",
      "[10, 14000] loss: 0.345\n",
      "[10, 16000] loss: 0.341\n",
      "[10, 18000] loss: 0.340\n",
      "[10, 20000] loss: 0.340\n",
      "[10, 22000] loss: 0.337\n",
      "Accuracy on dev set:90.127\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.341\n",
      "[11,  4000] loss: 0.344\n",
      "[11,  6000] loss: 0.336\n",
      "[11,  8000] loss: 0.340\n",
      "[11, 10000] loss: 0.338\n",
      "[11, 12000] loss: 0.332\n",
      "[11, 14000] loss: 0.333\n",
      "[11, 16000] loss: 0.342\n",
      "[11, 18000] loss: 0.340\n",
      "[11, 20000] loss: 0.335\n",
      "[11, 22000] loss: 0.330\n",
      "Accuracy on dev set:90.544\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.340\n",
      "[12,  4000] loss: 0.330\n",
      "[12,  6000] loss: 0.333\n",
      "[12,  8000] loss: 0.336\n",
      "[12, 10000] loss: 0.340\n",
      "[12, 12000] loss: 0.333\n",
      "[12, 14000] loss: 0.337\n",
      "[12, 16000] loss: 0.335\n",
      "[12, 18000] loss: 0.329\n",
      "[12, 20000] loss: 0.335\n",
      "[12, 22000] loss: 0.323\n",
      "Accuracy on dev set:90.766\n",
      "=> Saving a new best. Epoch: 12\n",
      "[13,  2000] loss: 0.332\n",
      "[13,  4000] loss: 0.323\n",
      "[13,  6000] loss: 0.336\n",
      "[13,  8000] loss: 0.327\n",
      "[13, 10000] loss: 0.333\n",
      "[13, 12000] loss: 0.335\n",
      "[13, 14000] loss: 0.334\n",
      "[13, 16000] loss: 0.320\n",
      "[13, 18000] loss: 0.336\n",
      "[13, 20000] loss: 0.328\n",
      "[13, 22000] loss: 0.331\n",
      "Accuracy on dev set:90.147\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.324\n",
      "[14,  4000] loss: 0.327\n",
      "[14,  6000] loss: 0.331\n",
      "[14,  8000] loss: 0.325\n",
      "[14, 10000] loss: 0.325\n",
      "[14, 12000] loss: 0.331\n",
      "[14, 14000] loss: 0.326\n",
      "[14, 16000] loss: 0.330\n",
      "[14, 18000] loss: 0.328\n",
      "[14, 20000] loss: 0.330\n",
      "[14, 22000] loss: 0.327\n",
      "Accuracy on dev set:89.97\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.325\n",
      "[15,  4000] loss: 0.323\n",
      "[15,  6000] loss: 0.322\n",
      "[15,  8000] loss: 0.320\n",
      "[15, 10000] loss: 0.331\n",
      "[15, 12000] loss: 0.329\n",
      "[15, 14000] loss: 0.320\n",
      "[15, 16000] loss: 0.331\n",
      "[15, 18000] loss: 0.332\n",
      "[15, 20000] loss: 0.319\n",
      "[15, 22000] loss: 0.322\n",
      "Accuracy on dev set:89.572\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.323\n",
      "[16,  4000] loss: 0.322\n",
      "[16,  6000] loss: 0.326\n",
      "[16,  8000] loss: 0.325\n",
      "[16, 10000] loss: 0.315\n",
      "[16, 12000] loss: 0.319\n",
      "[16, 14000] loss: 0.324\n",
      "[16, 16000] loss: 0.324\n",
      "[16, 18000] loss: 0.321\n",
      "[16, 20000] loss: 0.326\n",
      "[16, 22000] loss: 0.322\n",
      "Accuracy on dev set:90.205\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.324\n",
      "[17,  4000] loss: 0.323\n",
      "[17,  6000] loss: 0.316\n",
      "[17,  8000] loss: 0.324\n",
      "[17, 10000] loss: 0.320\n",
      "[17, 12000] loss: 0.329\n",
      "[17, 14000] loss: 0.313\n",
      "[17, 16000] loss: 0.315\n",
      "[17, 18000] loss: 0.317\n",
      "[17, 20000] loss: 0.324\n",
      "[17, 22000] loss: 0.316\n",
      "Accuracy on dev set:90.355\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.317\n",
      "[18,  4000] loss: 0.323\n",
      "[18,  6000] loss: 0.318\n",
      "[18,  8000] loss: 0.318\n",
      "[18, 10000] loss: 0.313\n",
      "[18, 12000] loss: 0.322\n",
      "[18, 14000] loss: 0.317\n",
      "[18, 16000] loss: 0.313\n",
      "[18, 18000] loss: 0.313\n",
      "[18, 20000] loss: 0.319\n",
      "[18, 22000] loss: 0.318\n",
      "Accuracy on dev set:90.05\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.313\n",
      "[19,  4000] loss: 0.317\n",
      "[19,  6000] loss: 0.316\n",
      "[19,  8000] loss: 0.313\n",
      "[19, 10000] loss: 0.316\n",
      "[19, 12000] loss: 0.306\n",
      "[19, 14000] loss: 0.310\n",
      "[19, 16000] loss: 0.316\n",
      "[19, 18000] loss: 0.319\n",
      "[19, 20000] loss: 0.318\n",
      "[19, 22000] loss: 0.314\n",
      "Accuracy on dev set:90.259\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.315\n",
      "[20,  4000] loss: 0.316\n",
      "[20,  6000] loss: 0.317\n",
      "[20,  8000] loss: 0.308\n",
      "[20, 10000] loss: 0.315\n",
      "[20, 12000] loss: 0.310\n",
      "[20, 14000] loss: 0.310\n",
      "[20, 16000] loss: 0.316\n",
      "[20, 18000] loss: 0.308\n",
      "[20, 20000] loss: 0.311\n",
      "[20, 22000] loss: 0.311\n",
      "Accuracy on dev set:90.462\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.316\n",
      "[21,  4000] loss: 0.309\n",
      "[21,  6000] loss: 0.316\n",
      "[21,  8000] loss: 0.306\n",
      "[21, 10000] loss: 0.312\n",
      "[21, 12000] loss: 0.311\n",
      "[21, 14000] loss: 0.313\n",
      "[21, 16000] loss: 0.306\n",
      "[21, 18000] loss: 0.309\n",
      "[21, 20000] loss: 0.307\n",
      "[21, 22000] loss: 0.307\n",
      "Accuracy on dev set:90.125\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.313\n",
      "[22,  4000] loss: 0.307\n",
      "[22,  6000] loss: 0.306\n",
      "[22,  8000] loss: 0.299\n",
      "[22, 10000] loss: 0.317\n",
      "[22, 12000] loss: 0.306\n",
      "[22, 14000] loss: 0.305\n",
      "[22, 16000] loss: 0.307\n",
      "[22, 18000] loss: 0.310\n",
      "[22, 20000] loss: 0.309\n",
      "[22, 22000] loss: 0.309\n",
      "Accuracy on dev set:90.458\n",
      "=> Validation accuracy did not improve. Epoch: 22\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 90.12 | 89.45 | 87.92 | 90.76 | 91.04 | 89.46 |    22    |   88.695   |\n",
      "|      |       |   1   |       |   3   |       |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 90.90 | 88.26 | 86.85 | 89.34 | 89.97 | 91.60 |    12    |   90.766   |\n",
      "|      |   8   |   3   |   7   |   1   |   3   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF4\n",
      "Fold: 3\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 869368x161\n",
      "Testset (L) fold228 shape: 96642x161\n",
      "Testset (U) fold228 shape: 254602x161\n",
      "\n",
      "Train Set dimension: 21734\n",
      "Dev Set dimension: 5433\n",
      "Test Set (L) dimension: 3020\n",
      "Test Set (U) dimension: 7956\n",
      "Accuracy on test set before training: 43.442\n",
      "\n",
      "[1,  2000] loss: 0.796\n",
      "[1,  4000] loss: 0.561\n",
      "[1,  6000] loss: 0.552\n",
      "[1,  8000] loss: 0.531\n",
      "[1, 10000] loss: 0.530\n",
      "[1, 12000] loss: 0.519\n",
      "[1, 14000] loss: 0.504\n",
      "[1, 16000] loss: 0.497\n",
      "[1, 18000] loss: 0.491\n",
      "[1, 20000] loss: 0.480\n",
      "Accuracy on dev set:88.968\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.475\n",
      "[2,  4000] loss: 0.476\n",
      "[2,  6000] loss: 0.463\n",
      "[2,  8000] loss: 0.462\n",
      "[2, 10000] loss: 0.459\n",
      "[2, 12000] loss: 0.448\n",
      "[2, 14000] loss: 0.450\n",
      "[2, 16000] loss: 0.444\n",
      "[2, 18000] loss: 0.433\n",
      "[2, 20000] loss: 0.440\n",
      "Accuracy on dev set:89.771\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.437\n",
      "[3,  4000] loss: 0.432\n",
      "[3,  6000] loss: 0.430\n",
      "[3,  8000] loss: 0.428\n",
      "[3, 10000] loss: 0.433\n",
      "[3, 12000] loss: 0.418\n",
      "[3, 14000] loss: 0.421\n",
      "[3, 16000] loss: 0.423\n",
      "[3, 18000] loss: 0.419\n",
      "[3, 20000] loss: 0.411\n",
      "Accuracy on dev set:89.943\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.418\n",
      "[4,  4000] loss: 0.412\n",
      "[4,  6000] loss: 0.413\n",
      "[4,  8000] loss: 0.404\n",
      "[4, 10000] loss: 0.408\n",
      "[4, 12000] loss: 0.409\n",
      "[4, 14000] loss: 0.406\n",
      "[4, 16000] loss: 0.411\n",
      "[4, 18000] loss: 0.403\n",
      "[4, 20000] loss: 0.403\n",
      "Accuracy on dev set:90.374\n",
      "=> Saving a new best. Epoch: 4\n",
      "[5,  2000] loss: 0.398\n",
      "[5,  4000] loss: 0.396\n",
      "[5,  6000] loss: 0.399\n",
      "[5,  8000] loss: 0.396\n",
      "[5, 10000] loss: 0.394\n",
      "[5, 12000] loss: 0.396\n",
      "[5, 14000] loss: 0.394\n",
      "[5, 16000] loss: 0.393\n",
      "[5, 18000] loss: 0.395\n",
      "[5, 20000] loss: 0.401\n",
      "Accuracy on dev set:90.086\n",
      "=> Validation accuracy did not improve. Epoch: 5\n",
      "[6,  2000] loss: 0.394\n",
      "[6,  4000] loss: 0.395\n",
      "[6,  6000] loss: 0.393\n",
      "[6,  8000] loss: 0.389\n",
      "[6, 10000] loss: 0.389\n",
      "[6, 12000] loss: 0.392\n",
      "[6, 14000] loss: 0.388\n",
      "[6, 16000] loss: 0.378\n",
      "[6, 18000] loss: 0.383\n",
      "[6, 20000] loss: 0.386\n",
      "Accuracy on dev set:90.337\n",
      "=> Validation accuracy did not improve. Epoch: 6\n",
      "[7,  2000] loss: 0.383\n",
      "[7,  4000] loss: 0.387\n",
      "[7,  6000] loss: 0.384\n",
      "[7,  8000] loss: 0.388\n",
      "[7, 10000] loss: 0.377\n",
      "[7, 12000] loss: 0.379\n",
      "[7, 14000] loss: 0.381\n",
      "[7, 16000] loss: 0.383\n",
      "[7, 18000] loss: 0.380\n",
      "[7, 20000] loss: 0.375\n",
      "Accuracy on dev set:89.989\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.377\n",
      "[8,  4000] loss: 0.387\n",
      "[8,  6000] loss: 0.373\n",
      "[8,  8000] loss: 0.380\n",
      "[8, 10000] loss: 0.371\n",
      "[8, 12000] loss: 0.374\n",
      "[8, 14000] loss: 0.372\n",
      "[8, 16000] loss: 0.379\n",
      "[8, 18000] loss: 0.374\n",
      "[8, 20000] loss: 0.375\n",
      "Accuracy on dev set:89.852\n",
      "=> Validation accuracy did not improve. Epoch: 8\n",
      "[9,  2000] loss: 0.371\n",
      "[9,  4000] loss: 0.375\n",
      "[9,  6000] loss: 0.370\n",
      "[9,  8000] loss: 0.367\n",
      "[9, 10000] loss: 0.369\n",
      "[9, 12000] loss: 0.370\n",
      "[9, 14000] loss: 0.372\n",
      "[9, 16000] loss: 0.374\n",
      "[9, 18000] loss: 0.368\n",
      "[9, 20000] loss: 0.368\n",
      "Accuracy on dev set:89.662\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.365\n",
      "[10,  4000] loss: 0.363\n",
      "[10,  6000] loss: 0.361\n",
      "[10,  8000] loss: 0.371\n",
      "[10, 10000] loss: 0.369\n",
      "[10, 12000] loss: 0.368\n",
      "[10, 14000] loss: 0.364\n",
      "[10, 16000] loss: 0.363\n",
      "[10, 18000] loss: 0.360\n",
      "[10, 20000] loss: 0.364\n",
      "Accuracy on dev set:89.949\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.367\n",
      "[11,  4000] loss: 0.367\n",
      "[11,  6000] loss: 0.364\n",
      "[11,  8000] loss: 0.360\n",
      "[11, 10000] loss: 0.362\n",
      "[11, 12000] loss: 0.361\n",
      "[11, 14000] loss: 0.366\n",
      "[11, 16000] loss: 0.356\n",
      "[11, 18000] loss: 0.350\n",
      "[11, 20000] loss: 0.361\n",
      "Accuracy on dev set:90.276\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.359\n",
      "[12,  4000] loss: 0.363\n",
      "[12,  6000] loss: 0.357\n",
      "[12,  8000] loss: 0.362\n",
      "[12, 10000] loss: 0.354\n",
      "[12, 12000] loss: 0.356\n",
      "[12, 14000] loss: 0.356\n",
      "[12, 16000] loss: 0.356\n",
      "[12, 18000] loss: 0.365\n",
      "[12, 20000] loss: 0.356\n",
      "Accuracy on dev set:90.655\n",
      "=> Saving a new best. Epoch: 12\n",
      "[13,  2000] loss: 0.355\n",
      "[13,  4000] loss: 0.357\n",
      "[13,  6000] loss: 0.360\n",
      "[13,  8000] loss: 0.352\n",
      "[13, 10000] loss: 0.358\n",
      "[13, 12000] loss: 0.353\n",
      "[13, 14000] loss: 0.349\n",
      "[13, 16000] loss: 0.349\n",
      "[13, 18000] loss: 0.357\n",
      "[13, 20000] loss: 0.356\n",
      "Accuracy on dev set:89.437\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.351\n",
      "[14,  4000] loss: 0.360\n",
      "[14,  6000] loss: 0.352\n",
      "[14,  8000] loss: 0.351\n",
      "[14, 10000] loss: 0.342\n",
      "[14, 12000] loss: 0.353\n",
      "[14, 14000] loss: 0.356\n",
      "[14, 16000] loss: 0.357\n",
      "[14, 18000] loss: 0.343\n",
      "[14, 20000] loss: 0.348\n",
      "Accuracy on dev set:90.237\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.351\n",
      "[15,  4000] loss: 0.345\n",
      "[15,  6000] loss: 0.351\n",
      "[15,  8000] loss: 0.342\n",
      "[15, 10000] loss: 0.347\n",
      "[15, 12000] loss: 0.342\n",
      "[15, 14000] loss: 0.358\n",
      "[15, 16000] loss: 0.352\n",
      "[15, 18000] loss: 0.344\n",
      "[15, 20000] loss: 0.343\n",
      "Accuracy on dev set:89.469\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.344\n",
      "[16,  4000] loss: 0.345\n",
      "[16,  6000] loss: 0.349\n",
      "[16,  8000] loss: 0.352\n",
      "[16, 10000] loss: 0.341\n",
      "[16, 12000] loss: 0.345\n",
      "[16, 14000] loss: 0.342\n",
      "[16, 16000] loss: 0.337\n",
      "[16, 18000] loss: 0.345\n",
      "[16, 20000] loss: 0.348\n",
      "Accuracy on dev set:89.629\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.346\n",
      "[17,  4000] loss: 0.349\n",
      "[17,  6000] loss: 0.339\n",
      "[17,  8000] loss: 0.342\n",
      "[17, 10000] loss: 0.339\n",
      "[17, 12000] loss: 0.341\n",
      "[17, 14000] loss: 0.343\n",
      "[17, 16000] loss: 0.343\n",
      "[17, 18000] loss: 0.337\n",
      "[17, 20000] loss: 0.342\n",
      "Accuracy on dev set:89.453\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.344\n",
      "[18,  4000] loss: 0.341\n",
      "[18,  6000] loss: 0.335\n",
      "[18,  8000] loss: 0.343\n",
      "[18, 10000] loss: 0.340\n",
      "[18, 12000] loss: 0.345\n",
      "[18, 14000] loss: 0.340\n",
      "[18, 16000] loss: 0.334\n",
      "[18, 18000] loss: 0.342\n",
      "[18, 20000] loss: 0.327\n",
      "Accuracy on dev set:90.126\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.324\n",
      "[19,  4000] loss: 0.339\n",
      "[19,  6000] loss: 0.330\n",
      "[19,  8000] loss: 0.336\n",
      "[19, 10000] loss: 0.342\n",
      "[19, 12000] loss: 0.342\n",
      "[19, 14000] loss: 0.349\n",
      "[19, 16000] loss: 0.333\n",
      "[19, 18000] loss: 0.337\n",
      "[19, 20000] loss: 0.335\n",
      "Accuracy on dev set:88.792\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.335\n",
      "[20,  4000] loss: 0.336\n",
      "[20,  6000] loss: 0.333\n",
      "[20,  8000] loss: 0.333\n",
      "[20, 10000] loss: 0.332\n",
      "[20, 12000] loss: 0.334\n",
      "[20, 14000] loss: 0.337\n",
      "[20, 16000] loss: 0.337\n",
      "[20, 18000] loss: 0.331\n",
      "[20, 20000] loss: 0.339\n",
      "Accuracy on dev set:88.792\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.333\n",
      "[21,  4000] loss: 0.338\n",
      "[21,  6000] loss: 0.329\n",
      "[21,  8000] loss: 0.330\n",
      "[21, 10000] loss: 0.330\n",
      "[21, 12000] loss: 0.339\n",
      "[21, 14000] loss: 0.335\n",
      "[21, 16000] loss: 0.332\n",
      "[21, 18000] loss: 0.329\n",
      "[21, 20000] loss: 0.330\n",
      "Accuracy on dev set:89.517\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.331\n",
      "[22,  4000] loss: 0.330\n",
      "[22,  6000] loss: 0.332\n",
      "[22,  8000] loss: 0.321\n",
      "[22, 10000] loss: 0.324\n",
      "[22, 12000] loss: 0.327\n",
      "[22, 14000] loss: 0.330\n",
      "[22, 16000] loss: 0.328\n",
      "[22, 18000] loss: 0.333\n",
      "[22, 20000] loss: 0.335\n",
      "Accuracy on dev set:89.955\n",
      "=> Validation accuracy did not improve. Epoch: 22\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 90.12 | 89.45 | 87.92 | 90.76 | 91.04 | 89.46 |    22    |   88.695   |\n",
      "|      |       |   1   |       |   3   |       |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 90.90 | 88.26 | 86.85 | 89.34 | 89.97 | 91.60 |    12    |   90.766   |\n",
      "|      |   8   |   3   |   7   |   1   |   3   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 90.14 | 90.33 | 89.50 | 90.97 | 85.72 | 93.42 |    12    |   90.655   |\n",
      "|      |   9   |   7   |   5   |   9   |   2   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF4\n",
      "Fold: 4\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 885991x161\n",
      "Testset (L) fold228 shape: 98489x161\n",
      "Testset (U) fold228 shape: 236132x161\n",
      "\n",
      "Train Set dimension: 22149\n",
      "Dev Set dimension: 5537\n",
      "Test Set (L) dimension: 3077\n",
      "Test Set (U) dimension: 7379\n",
      "Accuracy on test set before training: 45.944\n",
      "\n",
      "[1,  2000] loss: 0.787\n",
      "[1,  4000] loss: 0.558\n",
      "[1,  6000] loss: 0.546\n",
      "[1,  8000] loss: 0.536\n",
      "[1, 10000] loss: 0.535\n",
      "[1, 12000] loss: 0.519\n",
      "[1, 14000] loss: 0.517\n",
      "[1, 16000] loss: 0.505\n",
      "[1, 18000] loss: 0.502\n",
      "[1, 20000] loss: 0.482\n",
      "[1, 22000] loss: 0.476\n",
      "Accuracy on dev set:87.488\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.479\n",
      "[2,  4000] loss: 0.467\n",
      "[2,  6000] loss: 0.459\n",
      "[2,  8000] loss: 0.460\n",
      "[2, 10000] loss: 0.458\n",
      "[2, 12000] loss: 0.453\n",
      "[2, 14000] loss: 0.456\n",
      "[2, 16000] loss: 0.444\n",
      "[2, 18000] loss: 0.446\n",
      "[2, 20000] loss: 0.434\n",
      "[2, 22000] loss: 0.434\n",
      "Accuracy on dev set:88.79\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.434\n",
      "[3,  4000] loss: 0.443\n",
      "[3,  6000] loss: 0.429\n",
      "[3,  8000] loss: 0.421\n",
      "[3, 10000] loss: 0.423\n",
      "[3, 12000] loss: 0.426\n",
      "[3, 14000] loss: 0.425\n",
      "[3, 16000] loss: 0.425\n",
      "[3, 18000] loss: 0.423\n",
      "[3, 20000] loss: 0.421\n",
      "[3, 22000] loss: 0.419\n",
      "Accuracy on dev set:89.115\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.427\n",
      "[4,  4000] loss: 0.412\n",
      "[4,  6000] loss: 0.422\n",
      "[4,  8000] loss: 0.412\n",
      "[4, 10000] loss: 0.407\n",
      "[4, 12000] loss: 0.416\n",
      "[4, 14000] loss: 0.407\n",
      "[4, 16000] loss: 0.412\n",
      "[4, 18000] loss: 0.408\n",
      "[4, 20000] loss: 0.413\n",
      "[4, 22000] loss: 0.407\n",
      "Accuracy on dev set:88.791\n",
      "=> Validation accuracy did not improve. Epoch: 4\n",
      "[5,  2000] loss: 0.406\n",
      "[5,  4000] loss: 0.411\n",
      "[5,  6000] loss: 0.413\n",
      "[5,  8000] loss: 0.406\n",
      "[5, 10000] loss: 0.402\n",
      "[5, 12000] loss: 0.405\n",
      "[5, 14000] loss: 0.395\n",
      "[5, 16000] loss: 0.413\n",
      "[5, 18000] loss: 0.404\n",
      "[5, 20000] loss: 0.401\n",
      "[5, 22000] loss: 0.398\n",
      "Accuracy on dev set:89.758\n",
      "=> Saving a new best. Epoch: 5\n",
      "[6,  2000] loss: 0.395\n",
      "[6,  4000] loss: 0.401\n",
      "[6,  6000] loss: 0.411\n",
      "[6,  8000] loss: 0.401\n",
      "[6, 10000] loss: 0.395\n",
      "[6, 12000] loss: 0.394\n",
      "[6, 14000] loss: 0.400\n",
      "[6, 16000] loss: 0.397\n",
      "[6, 18000] loss: 0.393\n",
      "[6, 20000] loss: 0.396\n",
      "[6, 22000] loss: 0.392\n",
      "Accuracy on dev set:89.814\n",
      "=> Saving a new best. Epoch: 6\n",
      "[7,  2000] loss: 0.397\n",
      "[7,  4000] loss: 0.397\n",
      "[7,  6000] loss: 0.393\n",
      "[7,  8000] loss: 0.396\n",
      "[7, 10000] loss: 0.383\n",
      "[7, 12000] loss: 0.392\n",
      "[7, 14000] loss: 0.386\n",
      "[7, 16000] loss: 0.397\n",
      "[7, 18000] loss: 0.388\n",
      "[7, 20000] loss: 0.388\n",
      "[7, 22000] loss: 0.391\n",
      "Accuracy on dev set:89.323\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.384\n",
      "[8,  4000] loss: 0.391\n",
      "[8,  6000] loss: 0.386\n",
      "[8,  8000] loss: 0.388\n",
      "[8, 10000] loss: 0.385\n",
      "[8, 12000] loss: 0.385\n",
      "[8, 14000] loss: 0.386\n",
      "[8, 16000] loss: 0.393\n",
      "[8, 18000] loss: 0.376\n",
      "[8, 20000] loss: 0.382\n",
      "[8, 22000] loss: 0.388\n",
      "Accuracy on dev set:90.195\n",
      "=> Saving a new best. Epoch: 8\n",
      "[9,  2000] loss: 0.381\n",
      "[9,  4000] loss: 0.379\n",
      "[9,  6000] loss: 0.378\n",
      "[9,  8000] loss: 0.380\n",
      "[9, 10000] loss: 0.381\n",
      "[9, 12000] loss: 0.388\n",
      "[9, 14000] loss: 0.373\n",
      "[9, 16000] loss: 0.383\n",
      "[9, 18000] loss: 0.385\n",
      "[9, 20000] loss: 0.380\n",
      "[9, 22000] loss: 0.383\n",
      "Accuracy on dev set:89.726\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.376\n",
      "[10,  4000] loss: 0.380\n",
      "[10,  6000] loss: 0.378\n",
      "[10,  8000] loss: 0.374\n",
      "[10, 10000] loss: 0.368\n",
      "[10, 12000] loss: 0.380\n",
      "[10, 14000] loss: 0.382\n",
      "[10, 16000] loss: 0.382\n",
      "[10, 18000] loss: 0.373\n",
      "[10, 20000] loss: 0.375\n",
      "[10, 22000] loss: 0.377\n",
      "Accuracy on dev set:89.944\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.374\n",
      "[11,  4000] loss: 0.373\n",
      "[11,  6000] loss: 0.380\n",
      "[11,  8000] loss: 0.373\n",
      "[11, 10000] loss: 0.370\n",
      "[11, 12000] loss: 0.372\n",
      "[11, 14000] loss: 0.366\n",
      "[11, 16000] loss: 0.377\n",
      "[11, 18000] loss: 0.374\n",
      "[11, 20000] loss: 0.374\n",
      "[11, 22000] loss: 0.371\n",
      "Accuracy on dev set:90.137\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.367\n",
      "[12,  4000] loss: 0.374\n",
      "[12,  6000] loss: 0.372\n",
      "[12,  8000] loss: 0.370\n",
      "[12, 10000] loss: 0.374\n",
      "[12, 12000] loss: 0.370\n",
      "[12, 14000] loss: 0.369\n",
      "[12, 16000] loss: 0.368\n",
      "[12, 18000] loss: 0.362\n",
      "[12, 20000] loss: 0.372\n",
      "[12, 22000] loss: 0.364\n",
      "Accuracy on dev set:90.518\n",
      "=> Saving a new best. Epoch: 12\n",
      "[13,  2000] loss: 0.363\n",
      "[13,  4000] loss: 0.364\n",
      "[13,  6000] loss: 0.370\n",
      "[13,  8000] loss: 0.364\n",
      "[13, 10000] loss: 0.366\n",
      "[13, 12000] loss: 0.363\n",
      "[13, 14000] loss: 0.374\n",
      "[13, 16000] loss: 0.362\n",
      "[13, 18000] loss: 0.368\n",
      "[13, 20000] loss: 0.369\n",
      "[13, 22000] loss: 0.365\n",
      "Accuracy on dev set:89.514\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "[14,  2000] loss: 0.360\n",
      "[14,  4000] loss: 0.363\n",
      "[14,  6000] loss: 0.363\n",
      "[14,  8000] loss: 0.362\n",
      "[14, 10000] loss: 0.366\n",
      "[14, 12000] loss: 0.364\n",
      "[14, 14000] loss: 0.368\n",
      "[14, 16000] loss: 0.358\n",
      "[14, 18000] loss: 0.366\n",
      "[14, 20000] loss: 0.368\n",
      "[14, 22000] loss: 0.358\n",
      "Accuracy on dev set:89.024\n",
      "=> Validation accuracy did not improve. Epoch: 14\n",
      "[15,  2000] loss: 0.367\n",
      "[15,  4000] loss: 0.364\n",
      "[15,  6000] loss: 0.362\n",
      "[15,  8000] loss: 0.362\n",
      "[15, 10000] loss: 0.357\n",
      "[15, 12000] loss: 0.362\n",
      "[15, 14000] loss: 0.363\n",
      "[15, 16000] loss: 0.362\n",
      "[15, 18000] loss: 0.356\n",
      "[15, 20000] loss: 0.357\n",
      "[15, 22000] loss: 0.351\n",
      "Accuracy on dev set:89.451\n",
      "=> Validation accuracy did not improve. Epoch: 15\n",
      "[16,  2000] loss: 0.358\n",
      "[16,  4000] loss: 0.364\n",
      "[16,  6000] loss: 0.353\n",
      "[16,  8000] loss: 0.357\n",
      "[16, 10000] loss: 0.355\n",
      "[16, 12000] loss: 0.358\n",
      "[16, 14000] loss: 0.355\n",
      "[16, 16000] loss: 0.367\n",
      "[16, 18000] loss: 0.358\n",
      "[16, 20000] loss: 0.350\n",
      "[16, 22000] loss: 0.360\n",
      "Accuracy on dev set:89.85\n",
      "=> Validation accuracy did not improve. Epoch: 16\n",
      "[17,  2000] loss: 0.359\n",
      "[17,  4000] loss: 0.354\n",
      "[17,  6000] loss: 0.358\n",
      "[17,  8000] loss: 0.354\n",
      "[17, 10000] loss: 0.352\n",
      "[17, 12000] loss: 0.356\n",
      "[17, 14000] loss: 0.357\n",
      "[17, 16000] loss: 0.353\n",
      "[17, 18000] loss: 0.358\n",
      "[17, 20000] loss: 0.357\n",
      "[17, 22000] loss: 0.346\n",
      "Accuracy on dev set:88.884\n",
      "=> Validation accuracy did not improve. Epoch: 17\n",
      "[18,  2000] loss: 0.351\n",
      "[18,  4000] loss: 0.348\n",
      "[18,  6000] loss: 0.352\n",
      "[18,  8000] loss: 0.355\n",
      "[18, 10000] loss: 0.357\n",
      "[18, 12000] loss: 0.360\n",
      "[18, 14000] loss: 0.347\n",
      "[18, 16000] loss: 0.348\n",
      "[18, 18000] loss: 0.351\n",
      "[18, 20000] loss: 0.355\n",
      "[18, 22000] loss: 0.353\n",
      "Accuracy on dev set:90.146\n",
      "=> Validation accuracy did not improve. Epoch: 18\n",
      "[19,  2000] loss: 0.354\n",
      "[19,  4000] loss: 0.350\n",
      "[19,  6000] loss: 0.345\n",
      "[19,  8000] loss: 0.349\n",
      "[19, 10000] loss: 0.353\n",
      "[19, 12000] loss: 0.352\n",
      "[19, 14000] loss: 0.353\n",
      "[19, 16000] loss: 0.350\n",
      "[19, 18000] loss: 0.351\n",
      "[19, 20000] loss: 0.351\n",
      "[19, 22000] loss: 0.346\n",
      "Accuracy on dev set:90.272\n",
      "=> Validation accuracy did not improve. Epoch: 19\n",
      "[20,  2000] loss: 0.347\n",
      "[20,  4000] loss: 0.343\n",
      "[20,  6000] loss: 0.347\n",
      "[20,  8000] loss: 0.347\n",
      "[20, 10000] loss: 0.343\n",
      "[20, 12000] loss: 0.352\n",
      "[20, 14000] loss: 0.350\n",
      "[20, 16000] loss: 0.352\n",
      "[20, 18000] loss: 0.348\n",
      "[20, 20000] loss: 0.347\n",
      "[20, 22000] loss: 0.349\n",
      "Accuracy on dev set:88.835\n",
      "=> Validation accuracy did not improve. Epoch: 20\n",
      "[21,  2000] loss: 0.349\n",
      "[21,  4000] loss: 0.339\n",
      "[21,  6000] loss: 0.343\n",
      "[21,  8000] loss: 0.344\n",
      "[21, 10000] loss: 0.352\n",
      "[21, 12000] loss: 0.342\n",
      "[21, 14000] loss: 0.342\n",
      "[21, 16000] loss: 0.353\n",
      "[21, 18000] loss: 0.345\n",
      "[21, 20000] loss: 0.346\n",
      "[21, 22000] loss: 0.345\n",
      "Accuracy on dev set:90.119\n",
      "=> Validation accuracy did not improve. Epoch: 21\n",
      "[22,  2000] loss: 0.333\n",
      "[22,  4000] loss: 0.342\n",
      "[22,  6000] loss: 0.344\n",
      "[22,  8000] loss: 0.345\n",
      "[22, 10000] loss: 0.347\n",
      "[22, 12000] loss: 0.343\n",
      "[22, 14000] loss: 0.348\n",
      "[22, 16000] loss: 0.351\n",
      "[22, 18000] loss: 0.340\n",
      "[22, 20000] loss: 0.338\n",
      "[22, 22000] loss: 0.342\n",
      "Accuracy on dev set:89.726\n",
      "=> Validation accuracy did not improve. Epoch: 22\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 90.12 | 89.45 | 87.92 | 90.76 | 91.04 | 89.46 |    22    |   88.695   |\n",
      "|      |       |   1   |       |   3   |       |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 90.90 | 88.26 | 86.85 | 89.34 | 89.97 | 91.60 |    12    |   90.766   |\n",
      "|      |   8   |   3   |   7   |   1   |   3   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 90.14 | 90.33 | 89.50 | 90.97 | 85.72 | 93.42 |    12    |   90.655   |\n",
      "|      |   9   |   7   |   5   |   9   |   2   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 89.29 | 88.44 | 84.61 | 91.72 | 85.46 | 92.12 |    12    |   90.518   |\n",
      "|      |   5   |   2   |   2   |   1   |   1   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "MODEL: FF4\n",
      "Fold: 5\n",
      "+++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "Trainset fold228 shape: 881308x161\n",
      "Testset (L) fold228 shape: 97968x161\n",
      "Testset (U) fold228 shape: 241336x161\n",
      "\n",
      "Train Set dimension: 22032\n",
      "Dev Set dimension: 5508\n",
      "Test Set (L) dimension: 3061\n",
      "Test Set (U) dimension: 7541\n",
      "Accuracy on test set before training: 43.57\n",
      "\n",
      "[1,  2000] loss: 0.837\n",
      "[1,  4000] loss: 0.612\n",
      "[1,  6000] loss: 0.604\n",
      "[1,  8000] loss: 0.587\n",
      "[1, 10000] loss: 0.581\n",
      "[1, 12000] loss: 0.566\n",
      "[1, 14000] loss: 0.552\n",
      "[1, 16000] loss: 0.539\n",
      "[1, 18000] loss: 0.535\n",
      "[1, 20000] loss: 0.516\n",
      "[1, 22000] loss: 0.521\n",
      "Accuracy on dev set:91.062\n",
      "=> Saving a new best. Epoch: 1\n",
      "[2,  2000] loss: 0.514\n",
      "[2,  4000] loss: 0.507\n",
      "[2,  6000] loss: 0.502\n",
      "[2,  8000] loss: 0.492\n",
      "[2, 10000] loss: 0.487\n",
      "[2, 12000] loss: 0.484\n",
      "[2, 14000] loss: 0.484\n",
      "[2, 16000] loss: 0.481\n",
      "[2, 18000] loss: 0.481\n",
      "[2, 20000] loss: 0.474\n",
      "[2, 22000] loss: 0.469\n",
      "Accuracy on dev set:91.382\n",
      "=> Saving a new best. Epoch: 2\n",
      "[3,  2000] loss: 0.470\n",
      "[3,  4000] loss: 0.464\n",
      "[3,  6000] loss: 0.457\n",
      "[3,  8000] loss: 0.462\n",
      "[3, 10000] loss: 0.460\n",
      "[3, 12000] loss: 0.449\n",
      "[3, 14000] loss: 0.457\n",
      "[3, 16000] loss: 0.455\n",
      "[3, 18000] loss: 0.455\n",
      "[3, 20000] loss: 0.445\n",
      "[3, 22000] loss: 0.454\n",
      "Accuracy on dev set:91.561\n",
      "=> Saving a new best. Epoch: 3\n",
      "[4,  2000] loss: 0.449\n",
      "[4,  4000] loss: 0.453\n",
      "[4,  6000] loss: 0.443\n",
      "[4,  8000] loss: 0.444\n",
      "[4, 10000] loss: 0.439\n",
      "[4, 12000] loss: 0.441\n",
      "[4, 14000] loss: 0.436\n",
      "[4, 16000] loss: 0.428\n",
      "[4, 18000] loss: 0.443\n",
      "[4, 20000] loss: 0.441\n",
      "[4, 22000] loss: 0.430\n",
      "Accuracy on dev set:91.34\n",
      "=> Validation accuracy did not improve. Epoch: 4\n",
      "[5,  2000] loss: 0.435\n",
      "[5,  4000] loss: 0.431\n",
      "[5,  6000] loss: 0.432\n",
      "[5,  8000] loss: 0.428\n",
      "[5, 10000] loss: 0.430\n",
      "[5, 12000] loss: 0.430\n",
      "[5, 14000] loss: 0.430\n",
      "[5, 16000] loss: 0.424\n",
      "[5, 18000] loss: 0.423\n",
      "[5, 20000] loss: 0.429\n",
      "[5, 22000] loss: 0.427\n",
      "Accuracy on dev set:91.144\n",
      "=> Validation accuracy did not improve. Epoch: 5\n",
      "[6,  2000] loss: 0.427\n",
      "[6,  4000] loss: 0.427\n",
      "[6,  6000] loss: 0.414\n",
      "[6,  8000] loss: 0.425\n",
      "[6, 10000] loss: 0.421\n",
      "[6, 12000] loss: 0.420\n",
      "[6, 14000] loss: 0.418\n",
      "[6, 16000] loss: 0.418\n",
      "[6, 18000] loss: 0.416\n",
      "[6, 20000] loss: 0.421\n",
      "[6, 22000] loss: 0.412\n",
      "Accuracy on dev set:91.239\n",
      "=> Validation accuracy did not improve. Epoch: 6\n",
      "[7,  2000] loss: 0.418\n",
      "[7,  4000] loss: 0.409\n",
      "[7,  6000] loss: 0.418\n",
      "[7,  8000] loss: 0.420\n",
      "[7, 10000] loss: 0.414\n",
      "[7, 12000] loss: 0.416\n",
      "[7, 14000] loss: 0.406\n",
      "[7, 16000] loss: 0.418\n",
      "[7, 18000] loss: 0.417\n",
      "[7, 20000] loss: 0.401\n",
      "[7, 22000] loss: 0.400\n",
      "Accuracy on dev set:90.396\n",
      "=> Validation accuracy did not improve. Epoch: 7\n",
      "[8,  2000] loss: 0.411\n",
      "[8,  4000] loss: 0.403\n",
      "[8,  6000] loss: 0.414\n",
      "[8,  8000] loss: 0.411\n",
      "[8, 10000] loss: 0.407\n",
      "[8, 12000] loss: 0.400\n",
      "[8, 14000] loss: 0.410\n",
      "[8, 16000] loss: 0.401\n",
      "[8, 18000] loss: 0.400\n",
      "[8, 20000] loss: 0.402\n",
      "[8, 22000] loss: 0.412\n",
      "Accuracy on dev set:90.262\n",
      "=> Validation accuracy did not improve. Epoch: 8\n",
      "[9,  2000] loss: 0.407\n",
      "[9,  4000] loss: 0.404\n",
      "[9,  6000] loss: 0.399\n",
      "[9,  8000] loss: 0.395\n",
      "[9, 10000] loss: 0.398\n",
      "[9, 12000] loss: 0.403\n",
      "[9, 14000] loss: 0.401\n",
      "[9, 16000] loss: 0.394\n",
      "[9, 18000] loss: 0.404\n",
      "[9, 20000] loss: 0.401\n",
      "[9, 22000] loss: 0.398\n",
      "Accuracy on dev set:90.504\n",
      "=> Validation accuracy did not improve. Epoch: 9\n",
      "[10,  2000] loss: 0.395\n",
      "[10,  4000] loss: 0.394\n",
      "[10,  6000] loss: 0.405\n",
      "[10,  8000] loss: 0.399\n",
      "[10, 10000] loss: 0.395\n",
      "[10, 12000] loss: 0.397\n",
      "[10, 14000] loss: 0.393\n",
      "[10, 16000] loss: 0.387\n",
      "[10, 18000] loss: 0.393\n",
      "[10, 20000] loss: 0.396\n",
      "[10, 22000] loss: 0.394\n",
      "Accuracy on dev set:90.209\n",
      "=> Validation accuracy did not improve. Epoch: 10\n",
      "[11,  2000] loss: 0.393\n",
      "[11,  4000] loss: 0.389\n",
      "[11,  6000] loss: 0.381\n",
      "[11,  8000] loss: 0.392\n",
      "[11, 10000] loss: 0.395\n",
      "[11, 12000] loss: 0.388\n",
      "[11, 14000] loss: 0.399\n",
      "[11, 16000] loss: 0.396\n",
      "[11, 18000] loss: 0.389\n",
      "[11, 20000] loss: 0.390\n",
      "[11, 22000] loss: 0.387\n",
      "Accuracy on dev set:88.794\n",
      "=> Validation accuracy did not improve. Epoch: 11\n",
      "[12,  2000] loss: 0.388\n",
      "[12,  4000] loss: 0.387\n",
      "[12,  6000] loss: 0.389\n",
      "[12,  8000] loss: 0.390\n",
      "[12, 10000] loss: 0.387\n",
      "[12, 12000] loss: 0.378\n",
      "[12, 14000] loss: 0.393\n",
      "[12, 16000] loss: 0.388\n",
      "[12, 18000] loss: 0.394\n",
      "[12, 20000] loss: 0.378\n",
      "[12, 22000] loss: 0.388\n",
      "Accuracy on dev set:90.397\n",
      "=> Validation accuracy did not improve. Epoch: 12\n",
      "[13,  2000] loss: 0.383\n",
      "[13,  4000] loss: 0.387\n",
      "[13,  6000] loss: 0.387\n",
      "[13,  8000] loss: 0.388\n",
      "[13, 10000] loss: 0.379\n",
      "[13, 12000] loss: 0.386\n",
      "[13, 14000] loss: 0.379\n",
      "[13, 16000] loss: 0.375\n",
      "[13, 18000] loss: 0.371\n",
      "[13, 20000] loss: 0.393\n",
      "[13, 22000] loss: 0.390\n",
      "Accuracy on dev set:89.87\n",
      "=> Validation accuracy did not improve. Epoch: 13\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "| Fold | Acc_L | Acc_U | R_0_U | R_1_U | R_0_L | R_1_L | Stop_epo | Accuracy_d |\n",
      "|      |       |       |       |       |       |       |    ch    |     ev     |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  1   | 90.12 | 89.45 | 87.92 | 90.76 | 91.04 | 89.46 |    22    |   88.695   |\n",
      "|      |       |   1   |       |   3   |       |   8   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  2   | 90.90 | 88.26 | 86.85 | 89.34 | 89.97 | 91.60 |    12    |   90.766   |\n",
      "|      |   8   |   3   |   7   |   1   |   3   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  3   | 90.14 | 90.33 | 89.50 | 90.97 | 85.72 | 93.42 |    12    |   90.655   |\n",
      "|      |   9   |   7   |   5   |   9   |   2   |   5   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  4   | 89.29 | 88.44 | 84.61 | 91.72 | 85.46 | 92.12 |    12    |   90.518   |\n",
      "|      |   5   |   2   |   2   |   1   |   1   |   3   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "|  5   | 88.84 | 91.09 | 90.59 | 91.47 | 86.34 | 90.70 |    3     |   91.561   |\n",
      "|      |   9   |       |   2   |   6   |   5   |   4   |          |            |\n",
      "+------+-------+-------+-------+-------+-------+-------+----------+------------+\n",
      "----------------------------------------------------------------------\n",
      "+--------------+--------+---------+\n",
      "|     FF4      |  Avg   | Std_dev |\n",
      "+--------------+--------+---------+\n",
      "|    Acc_U     | 89.517 |  1.084  |\n",
      "+--------------+--------+---------+\n",
      "|    Acc_L     | 89.864 |  0.72   |\n",
      "+--------------+--------+---------+\n",
      "|    P_0_U     | 88.528 |  1.237  |\n",
      "+--------------+--------+---------+\n",
      "|    R_0_U     | 87.897 |  2.084  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_0_U    | 88.195 |  1.225  |\n",
      "+--------------+--------+---------+\n",
      "|    P_1_U     | 90.302 |  1.809  |\n",
      "+--------------+--------+---------+\n",
      "|    R_1_U     | 90.856 |  0.831  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_1_U    | 90.567 |  0.998  |\n",
      "+--------------+--------+---------+\n",
      "|    P_0_L     | 88.328 |  1.581  |\n",
      "+--------------+--------+---------+\n",
      "|    R_0_L     | 87.708 |  2.327  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_0_L    | 87.982 |  0.928  |\n",
      "+--------------+--------+---------+\n",
      "|    P_1_L     | 91.043 |  1.566  |\n",
      "+--------------+--------+---------+\n",
      "|    R_1_L     | 91.465 |  1.331  |\n",
      "+--------------+--------+---------+\n",
      "|    F1_1_L    | 91.234 |  0.594  |\n",
      "+--------------+--------+---------+\n",
      "| Accuracy_dev | 90.439 |  0.944  |\n",
      "+--------------+--------+---------+\n",
      "Elapsed time: 1:33:23\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nmuscles=int((len(traindata.columns)-1)/spw)\n",
    "if use_cuda and not use_gputil and cuda_device!=None and torch.cuda.is_available():\n",
    "    with torch.cuda.device(cuda_device):\n",
    "        print('I am using CUDA: SUCCESS!')\n",
    "        train_test()\n",
    "else:\n",
    "    print('I am NOT using CUDA: SUCCESS!')\n",
    "    train_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
